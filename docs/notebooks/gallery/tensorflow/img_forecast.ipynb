{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "global-sherman",
   "metadata": {},
   "source": [
    "# TensorFlow: Image Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-philip",
   "metadata": {},
   "source": [
    "*Lunar Astronomy Forecasting Using a 5D Time Series of Shifting Windows.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-personal",
   "metadata": {},
   "source": [
    "![liberty](../../../images/banner/moons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-franchise",
   "metadata": {},
   "source": [
    "Although the pipeline runs successfully, this tutorial is considered a 'work in progress' in that the model architecture still needs a bit of work. Here we attempt an self-supervised *walk forward* with an autoencoder whose evaluation data is shifted 2 frames forward. The goal is to show an image to the model and have it infer what that image will look like 2 steps in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-stress",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea3053-7298-42a4-bfc4-a46a0aa76fb5",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bacd42-52c3-4c1c-a9b4-7117e5b4b00f",
   "metadata": {},
   "source": [
    "Reference [Example Datasets](example_datasets.ipynb) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119fe4e4-3779-47b8-aa74-e00154a0cccd",
   "metadata": {},
   "source": [
    "This dataset is comprised of:\n",
    "\n",
    "* *Features* = folder of images that represent a time series\n",
    "* *Target* = we will shift that time series forward 2 frames using a `window`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dcdd91f-edec-4539-9a89-2d4f0955d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc import datum\n",
    "from aiqc.orm import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccbbae5-06d0-4bc2-82c3-e64784e8c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Ingesting Images üñºÔ∏è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 117.16it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'remote_datum/image/liberty_moon/images'\n",
    "image_dataset = Dataset.Image.from_folder_pillow(folder_path=folder_path, ingest=False, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1863e52-8898-4ee5-93d3-f6fa8405c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_pillow = image_dataset.to_pillow(samples=[0,7,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558b7f19-ae0e-447f-a26d-d6a236adcac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAA8CAAAAAABXrYdAAACeUlEQVR4nO1W3U4TQRT+vjPD0halolRQRDEqJkTjjbfEC6/UF9An8AV8EJ/IN/DCCy8w0fhDUqChVEptd7szx4stMG1h2SbGkOhJNrM7M9+cvznfHkYUKvsEFMVEhITW7riC+wEICfrqUwWYyZkQS0CTF/RHMzzLQusjTr96/toGcwNFGvgXumrT2fX12TcbdvxoDlSORoaRlqb3nS0cL4ARoDzT/lAEgEAnQEBQPIcBZEL5D/kLEJu7SgBQcCjZBbSQGKo7C2pYVdni2BViUDiWg7oYN+i0mXMb5H8cYrMsnUh8OhhH1u3RhoxRw/WQ3YiMN5HReDA9NAZv4aU6txH744U8erwCOhEEWayLQkiAsE7Jgr6QANzCS6NF3ScBkPGPWPIg49dCWtFdDwhPEaEEfUN22eLO29V+bsRGqElptjbK5nTDVPW4SRmoc2sra1f8BNmn6srqs5rLhRyXi2a/eTruic3VoyMfrpc62qvN3FaMQ0PT1CIvMxZ5PZgKVQ/VyafPH+bF7gpCxhhlBy2bFsFy7AHIjfebCxfFm4EzJ/d8jC8Y0Fw2APzczGbXVoUrpRMtOmwD+6YEOFgFwEv3Hy+nwr3OuAYet206VfHwB2VVRffbQa/ethaRpFl6hnhLdEBrvaV2gn5FFED919S2t83aozjebR65Tg0eAIgxf5AmNuoqKuKNKVnd7e1UM8NV6QUK0gNQKISQRJfrpU1ZlHinuz0XtxJ76+ft7boBAaqPbn5P7zW60k/Bsk+rrkPjG53Uu/ai0etfekm5Rftwf7XxseTA1PbNdK3RVUkrfSoqrnOtbZe+mk5qkqnERRs2mn3y4N3Wb+ms7PWp/pfaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x60 at 0x18D1C4490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_pillow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0154371a-c565-4935-80ee-bd1b8c8dadf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAA8CAAAAAABXrYdAAACsklEQVR4nNVWW2sTQRg9Z3Y2m0vTtLVGUUpblCKFtg8iiv0n+lf8V4LvPgqC4IsKYlGw2qamJm3aJLs7nw+7m042s20iKDohZG5nznebM6GPWZuaGfGXINo9TUCmgRBId3ImFlodGQ1sSn0xO3m0m0xfse5Y/Gfz8l9BLg33ZPYJAMzS6qwznduddQnBRdGMQVV28DgXQW3TJpMkASgSyL42xixtxPY4XWfiPl0kprkbw9FIZ5BJhPK051pCwa00ldqNJ43nBeLjhAjubb15cVaQHwZOjDHiq4Lb74YAAIv0orjGChVmurIc86pAx+zNebqrIHkKXg5hrivJz+9osk1rW+3IYzrlMIwu4bRZHMdccZOniFjOhFkgGfcf1rFEQqaHkEBQTSHk5REimVz4aPdRzCyVhIzckzErkm4iajwcGFDUxVHWodnOFCsJml+3b0uRLwmKtOAk1MHms5JwqryMMvL+fL7l1rF8S72S4OHdbV9mYvHv3Dx8CW1fn0KFyAwbRu1IacPxwhVMVLJkr4ZEYkTUrZJIFsXRHqsZjP7XsN+uNAktuQDkX6BKFDN71qJ3+D43UB2v2F0AUisL6dUBwCz6b1trgYI/ibFZzuuAlOcJwKx3O71lX5mVmmQO2LD0PeIw0IKBUgAEy/cflHtaH3eUXYPpTkk0gzC10pkKJTgl2P4Sn+/HGqrqDYeKknwyX5KyIGDC9Q+x6Vd6AMNPPwYd0SfN7f6wu59FH4RAGUCZZKx615vxybDhDaiqWqOqNY/MfjWxTITGg4AUQAwZK9LrrSycVY8qG3Ly7aC/ZFpG7XCz+rNjhFSU8pbmTqMUaFA3ynptruR7Zm+v9WVwrEMsdLu+KWm9em21/WoeIYY60n4QhO0o1EIRpVDrLtY/m55RXgmq/9Ev1x+fvu79Aqbr86iXcGigAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x60 at 0x18D179ED0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_pillow[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4001b6b-8d9a-4838-b500-7467dbaa93ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAA8CAAAAAABXrYdAAACk0lEQVR4nOWW227TQBCG/3+8Tp1ETYFySFpxElUrIVQqcQHiikvegOfgLXgRHoiDkJBKC2oVlSJKkjYHJ/YOF+s6tuOg9K6iI0XJbubbmd35PWv6uKjJhYn/CjFlk3RfOg/hzF8sXST1MgCoJU4zKJWOMixftnQF53dpD/mKI1mNJdLhXHXNIjl6akW+mNgC2jE5LyajHEgA0CRdJrJcwDLqvbR1uapIUheTDv8pRVd7AtCMLGcFfN40k26kyWQuMXJODyQBuTZHMEwMSHECqkD0fNnFkdSliBZynDReadJgSzMpmHqMmm/3OsY9tcEiDO/v7Hx7r7SLI/BqYb9CWC6OuM3JUmgXrj6FQNx8I0iQefWYRiAASH93CEBEREiKiMznkruoW3tGaDYxMlNIIbNjAMC4925rQoO02Ux7kTK95XKh5NeHwCvfvs7pgPHTre3b8Qyiqlp+Ggqsb75uQHTqWdhtwR1QYjDsirHMzzN1yKFKABpHYlWa1dnEdPo7XUhVgWO5FVijJs1cS55lNZwQyXuF7H3evdGWzjT6tASZSEsNklg2AOA9/LTfagiN0XNznPucI6OqAeS6R6FdrbaH/orY9ZVil6DL3Y1iCRRx5KsCce3Jy9bAeKe/M8eU4dTdT9bUe4JB/ZSK8IfxDwYGWpNwLLn3Nrr6u5mzB72hDesmBng08I+sGUbbo7B/oCCgVFIBsa6vEADjYatj+0uVM2XVSBDUDE+Cw4rnltfEC6qAKi0FMjLNUX2id72wfXrQqB/35YVsrHQ7FqQQ8rium2t+4NGTes1r3TEVX35++fM9PBFvdHPQjkbxslkL7o2PG5gwNJHn+0HYG0cGUEuPwbi28ZVdK6hAZV+oj1Y/Dv8C9+LzLdApFt4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x60 at 0x18D1C43D0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_pillow[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ae46d-8931-4af8-accc-a25a7874fbf4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b213d-3f7c-4f05-a578-9359a3558b61",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41588813-0770-4da3-a221-6c44771c8823",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11823a0a-ab10-47f8-9061-56d6b2f3de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc.mlops import Pipeline, Input, Target, Stratifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from aiqc.utils.encoding import div255, mult255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a179660c-5999-4439-b423-df8215fc2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    inputs = Input(\n",
    "        dataset         = image_dataset\n",
    "        , window          = Input.Window(size_window=1, size_shift=2)\n",
    "        , encoders        = Input.Encoder(FunctionTransformer(div255, inverse_func=mult255))\n",
    "        , reshape_indices = (0,3,4)#reshape for Conv1D grayscale.\n",
    "    ),\n",
    "\n",
    "    stratifier = Stratifier(size_test=0.25)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f868cf-02a9-4082-9dd4-d84c6b25850a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788cff0-89ea-4ed0-8457-24cd2c7ee31d",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7f221-301e-44f1-b024-a5fe46a04ac2",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79e464cb-a2c3-4f22-898f-417f33f4c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc.mlops import Experiment, Architecture, Trainer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "capable-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):\n",
    "    m = tf.keras.models.Sequential()\n",
    "    m.add(l.Conv1D(64*hp['multiplier'], 3, activation=hp['activation'], padding='same'))\n",
    "    m.add(l.MaxPool1D( 2, padding='same'))\n",
    "    m.add(l.Conv1D(32*hp['multiplier'], 3, activation=hp['activation'], padding='same'))\n",
    "    m.add(l.MaxPool1D( 2, padding='same'))\n",
    "    m.add(l.Conv1D(16*hp['multiplier'], 3, activation=hp['activation'], padding='same'))\n",
    "    m.add(l.MaxPool1D( 2, padding='same'))\n",
    "\n",
    "    # decoding architecture\n",
    "    m.add(l.Conv1D(16*hp['multiplier'], 3, activation=hp['activation'], padding='same'))\n",
    "    m.add(l.UpSampling1D(2))\n",
    "    m.add(l.Conv1D(32*hp['multiplier'], 3, activation=hp['activation'], padding='same'))\n",
    "    m.add(l.UpSampling1D(2))\n",
    "    m.add(l.Conv1D(64*hp['multiplier'], 3, activation=hp['activation']))\n",
    "    m.add(l.UpSampling1D(2))\n",
    "    m.add(l.Conv1D(50, 3, activation='relu', padding='same'))# removing sigmoid\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "instant-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(\n",
    "    model, loser, optimizer,\n",
    "    train_features, train_label,\n",
    "    eval_features, eval_label,\n",
    "    **hp\n",
    "):\n",
    "    model.compile(\n",
    "        optimizer = optimizer\n",
    "        , loss    = loser\n",
    "        , metrics = ['mean_squared_error']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_features, train_label\n",
    "        , validation_data = (eval_features, eval_label)\n",
    "        , verbose         = 0\n",
    "        , batch_size      = hp['batch_size']\n",
    "        , callbacks       = [tf.keras.callbacks.History()]\n",
    "        , epochs          = hp['epoch_count']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "considerable-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(\n",
    "    epoch_count  = [150]\n",
    "    , batch_size = [1]\n",
    "    , cnn_init   = ['he_normal']\n",
    "    , activation = ['relu']\n",
    "    , multiplier = [3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "722597a3-f760-45fa-a8ad-12abe0bc0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    Architecture(\n",
    "        library           = \"keras\"\n",
    "        , analysis_type   = \"regression\"\n",
    "        , fn_build        = fn_build\n",
    "        , fn_train        = fn_train\n",
    "        , hyperparameters = hyperparameters\n",
    "    ),\n",
    "    \n",
    "    Trainer(\n",
    "        pipeline       = pipeline\n",
    "        , repeat_count = 1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "enclosed-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ Caching Splits üì¶: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 320.73it/s]\n",
      "üîÆ Training Models üîÆ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.66s/it]\n"
     ]
    }
   ],
   "source": [
    "experiment.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-canberra",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f8aa7-bf1a-4cce-8e3a-d856ea2aca9b",
   "metadata": {},
   "source": [
    "## Visualization & Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ed7ef-96ff-45c7-9cb6-851d65754938",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Dashboard](dashboard.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

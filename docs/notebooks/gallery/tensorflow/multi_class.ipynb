{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silver-toner",
   "metadata": {},
   "source": [
    "# TensorFlow: Tabular Classify Multi-Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3ba61-1298-4355-a5e0-fe278acd8c7d",
   "metadata": {},
   "source": [
    "*Categorizing Plant Species with Multi-Label Classification of Phenotypes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-robinson",
   "metadata": {},
   "source": [
    "![farming](../../../_static/images/banner/plants.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-turkish",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9eda3d-061f-44ab-bf1c-65e78e5ac641",
   "metadata": {},
   "source": [
    "Reference [Example Datasets](../../datasets.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-accident",
   "metadata": {},
   "source": [
    "This dataset is comprised of:\n",
    "\n",
    "* *Labels* = the species of the plant.\n",
    "* *Features* = phenotypes of the plant sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2dedec4-0ee0-4020-88e8-4e10fa3ac51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc import datum\n",
    "from aiqc.orm import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hindu-liquid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datum.to_pandas('iris.tsv')\n",
    "shared_dataset = Dataset.Tabular.from_pandas(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-breakfast",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-desperate",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272eb65-2326-40c4-95ea-43a7f3ad1ec7",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](../../api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "detailed-favor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aiqc.mlops import Pipeline, Input, Target, Stratifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb956d01-31e1-47b6-8de0-ef934c00f639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â””â”€â”€ Info - System overriding user input to set `sklearn_preprocess.sparse=False`.\n",
      "\tThis would have generated 'scipy.sparse.csr.csr_matrix', causing Keras training to fail.\n",
      "\n",
      "\n",
      "â””â”€â”€ Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "\tThis saves memory when concatenating the output of many encoders.\n",
      "\n",
      "Warning - The number of samples <117> in your training Split\n",
      "is not evenly divisible by the `fold_count` <5> you specified.\n",
      "This can result in misleading performance metrics for the last Fold.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    Input(\n",
    "        dataset  = shared_dataset,\n",
    "        encoders = Input.Encoder(\n",
    "            StandardScaler(),\n",
    "            dtypes = ['float64']\n",
    "        )\n",
    "    ),\n",
    "        \n",
    "    Target(\n",
    "        dataset   = shared_dataset\n",
    "        , column  = 'species'\n",
    "        , encoder = Target.Encoder(OneHotEncoder())\n",
    "    ),\n",
    "\n",
    "    Stratifier(\n",
    "        size_test    = 0.22\n",
    "        , fold_count = 5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-latest",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a25e74-2a2c-432d-98ac-3976c6e9fb74",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d5c85-89fe-4f46-a7d0-2e722cc4c472",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](../../api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd48ac94-8744-4078-bd94-bfe8c2836024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc.mlops import Experiment, Architecture, Trainer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "racial-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):\n",
    "    m = tf.keras.models.Sequential()\n",
    "    m.add(l.Input(shape=features_shape))\n",
    "    m.add(l.Dense(units=hp['neuron_count'], activation='relu', kernel_initializer='he_uniform'))\n",
    "    m.add(l.Dense(units=label_shape[0], activation='softmax'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "robust-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(\n",
    "    model, loser, optimizer,\n",
    "    train_features, train_label,\n",
    "    eval_features, eval_label,\n",
    "    **hp\n",
    "):\n",
    "    model.compile(\n",
    "        loss        = loser\n",
    "        , optimizer = optimizer\n",
    "        , metrics   = ['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        train_features, train_label\n",
    "        , validation_data = (eval_features, eval_label)\n",
    "        , verbose         = 0\n",
    "        , batch_size      = hp['batch_size']\n",
    "        , epochs          = hp['epoch_count']\n",
    "        , callbacks       = [tf.keras.callbacks.History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adaptive-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(\n",
    "    neuron_count    = [9, 12]\n",
    "    , batch_size    = [3]\n",
    "    , learning_rate = [0.03, 0.05]\n",
    "    , epoch_count   = [30, 60]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57d8f80-3209-4633-8b42-94a50b660f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    Architecture(\n",
    "        library           = \"keras\"\n",
    "        , analysis_type   = \"classification_multi\"\n",
    "        , fn_build        = fn_build\n",
    "        , fn_train        = fn_train\n",
    "        , hyperparameters = hyperparameters\n",
    "    ),\n",
    "    \n",
    "    Trainer(\n",
    "        pipeline       = pipeline\n",
    "        , repeat_count = 1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "treated-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Caching Splits - Fold #1 ðŸ“¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 303.85it/s]\n",
      "ðŸ“¦ Caching Splits - Fold #2 ðŸ“¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 433.21it/s]\n",
      "ðŸ“¦ Caching Splits - Fold #3 ðŸ“¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 415.58it/s]\n",
      "ðŸ“¦ Caching Splits - Fold #4 ðŸ“¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 356.13it/s]\n",
      "ðŸ“¦ Caching Splits - Fold #5 ðŸ“¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 447.23it/s]\n",
      "ðŸ”® Training Models - Fold #1 ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:31<00:00,  3.88s/it]\n",
      "ðŸ”® Training Models - Fold #2 ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:29<00:00,  3.72s/it]\n",
      "ðŸ”® Training Models - Fold #3 ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:34<00:00,  4.35s/it]\n",
      "ðŸ”® Training Models - Fold #4 ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:31<00:00,  4.00s/it]\n",
      "ðŸ”® Training Models - Fold #5 ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:32<00:00,  4.09s/it]\n"
     ]
    }
   ],
   "source": [
    "experiment.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9956d4c3-d352-41bf-a31f-6f7a59b27d74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b22f93-98b5-4b14-8b96-4e69531e5ffd",
   "metadata": {},
   "source": [
    "## Visualization & Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a5696-1635-4b06-a738-3ce5b96d6b04",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Dashboard](../../dashboard.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

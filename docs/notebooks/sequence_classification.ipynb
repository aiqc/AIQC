{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "endangered-screw",
   "metadata": {},
   "source": [
    "# Times Series/ Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-slovak",
   "metadata": {},
   "source": [
    "*Binary Detection of Epileptic Seizures Using a Sequence of Electroencephalography (EEG) Readings.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-barrier",
   "metadata": {},
   "source": [
    "![brain_waves](../images/brain_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-virtue",
   "metadata": {},
   "source": [
    "Sequence data structures contain many observations (rows) for each sample (e.g. site, sensor, or patient). They are often used for grouping time-based observations into what is called a time series. However, sequences can also represent biological sequences like DNA and RNA.\n",
    "\n",
    "The cardinality of *many observations per sample* changes the dimensionality of the data from 2D to 3D. This effectively adds an additional layer of complexity to all aspects of data preparation. In this notebook, you'll see that, once a `Dataset.Sequence` has been ingested, the AIQC API allows you to work with this 3D data as easily as if it were 2D. As an example, you can still apply encoders by dtype and column_name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-violence",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "female-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc\n",
    "from aiqc import datum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-strap",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-seven",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brazilian-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc import datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "placed-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('epilepsy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assigned-reduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_0</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_169</th>\n",
       "      <th>sensor_170</th>\n",
       "      <th>sensor_171</th>\n",
       "      <th>sensor_172</th>\n",
       "      <th>sensor_173</th>\n",
       "      <th>sensor_174</th>\n",
       "      <th>sensor_175</th>\n",
       "      <th>sensor_176</th>\n",
       "      <th>sensor_177</th>\n",
       "      <th>seizure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>183</td>\n",
       "      <td>125</td>\n",
       "      <td>47</td>\n",
       "      <td>-32</td>\n",
       "      <td>-73</td>\n",
       "      <td>-105</td>\n",
       "      <td>-99</td>\n",
       "      <td>-72</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-202</td>\n",
       "      <td>-303</td>\n",
       "      <td>-365</td>\n",
       "      <td>-389</td>\n",
       "      <td>-406</td>\n",
       "      <td>-401</td>\n",
       "      <td>-366</td>\n",
       "      <td>-251</td>\n",
       "      <td>-143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284</td>\n",
       "      <td>276</td>\n",
       "      <td>268</td>\n",
       "      <td>261</td>\n",
       "      <td>254</td>\n",
       "      <td>241</td>\n",
       "      <td>232</td>\n",
       "      <td>223</td>\n",
       "      <td>212</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>-19</td>\n",
       "      <td>-57</td>\n",
       "      <td>-91</td>\n",
       "      <td>-118</td>\n",
       "      <td>-131</td>\n",
       "      <td>-140</td>\n",
       "      <td>-148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>373</td>\n",
       "      <td>555</td>\n",
       "      <td>580</td>\n",
       "      <td>548</td>\n",
       "      <td>502</td>\n",
       "      <td>433</td>\n",
       "      <td>348</td>\n",
       "      <td>276</td>\n",
       "      <td>216</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>-1032</td>\n",
       "      <td>-1108</td>\n",
       "      <td>-803</td>\n",
       "      <td>-377</td>\n",
       "      <td>-13</td>\n",
       "      <td>172</td>\n",
       "      <td>246</td>\n",
       "      <td>206</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791</td>\n",
       "      <td>703</td>\n",
       "      <td>538</td>\n",
       "      <td>76</td>\n",
       "      <td>-535</td>\n",
       "      <td>-1065</td>\n",
       "      <td>-1297</td>\n",
       "      <td>-1018</td>\n",
       "      <td>-525</td>\n",
       "      <td>-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-396</td>\n",
       "      <td>135</td>\n",
       "      <td>493</td>\n",
       "      <td>601</td>\n",
       "      <td>559</td>\n",
       "      <td>400</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>-141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>436</td>\n",
       "      <td>473</td>\n",
       "      <td>508</td>\n",
       "      <td>546</td>\n",
       "      <td>587</td>\n",
       "      <td>615</td>\n",
       "      <td>623</td>\n",
       "      <td>615</td>\n",
       "      <td>596</td>\n",
       "      <td>574</td>\n",
       "      <td>...</td>\n",
       "      <td>637</td>\n",
       "      <td>644</td>\n",
       "      <td>646</td>\n",
       "      <td>650</td>\n",
       "      <td>656</td>\n",
       "      <td>653</td>\n",
       "      <td>648</td>\n",
       "      <td>628</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_0  sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  \\\n",
       "0       232       183       125        47       -32       -73      -105   \n",
       "1       284       276       268       261       254       241       232   \n",
       "2       373       555       580       548       502       433       348   \n",
       "3       791       703       538        76      -535     -1065     -1297   \n",
       "4       436       473       508       546       587       615       623   \n",
       "\n",
       "   sensor_7  sensor_8  sensor_9  ...  sensor_169  sensor_170  sensor_171  \\\n",
       "0       -99       -72       -33  ...        -202        -303        -365   \n",
       "1       223       212       206  ...          64          15         -19   \n",
       "2       276       216       182  ...       -1032       -1108        -803   \n",
       "3     -1018      -525       -13  ...        -396         135         493   \n",
       "4       615       596       574  ...         637         644         646   \n",
       "\n",
       "   sensor_172  sensor_173  sensor_174  sensor_175  sensor_176  sensor_177  \\\n",
       "0        -389        -406        -401        -366        -251        -143   \n",
       "1         -57         -91        -118        -131        -140        -148   \n",
       "2        -377         -13         172         246         206         156   \n",
       "3         601         559         400         193           3        -141   \n",
       "4         650         656         653         648         628         608   \n",
       "\n",
       "   seizure  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-offense",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-nancy",
   "metadata": {},
   "source": [
    "## a) High-Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-habitat",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ordinary-promotion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_df = df[['seizure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entitled-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ndarray3D = df.drop(columns=['seizure']).to_numpy().reshape(1000,178,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "elementary-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "conservative-destiny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Validating Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 680120.64it/s]\n",
      "‚è±Ô∏è Ingesting Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:08<00:00, 113.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['0']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitset = aiqc.Pipeline.Sequence.make(\n",
    "    \n",
    "    seq_ndarray3D = seq_ndarray3D\n",
    "    , seq_feature_encoders = [{\n",
    "        \"sklearn_preprocess\": StandardScaler()\n",
    "        , \"columns\": '0'\n",
    "    }]\n",
    "    \n",
    "    , tab_DF_or_path = label_df\n",
    "    , tab_label_column = 'seizure'\n",
    "\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "august-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "psychological-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        hp['neuron_count']\n",
    "        , input_shape=(features_shape[0], features_shape[1])\n",
    "    ))\n",
    "    model.add(Dense(units=label_shape[0], activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "artificial-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss=loser\n",
    "        , optimizer=optimizer\n",
    "        , metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        samples_train['features'], samples_train['labels']\n",
    "        , validation_data = (samples_evaluate['features'], samples_evaluate['labels'])\n",
    "        , verbose = 0\n",
    "        , batch_size = hp['batch_size']\n",
    "        , epochs = hp['epochs']\n",
    "        , callbacks = [History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "chubby-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"neuron_count\": [25]\n",
    "    , \"batch_size\": [8]\n",
    "    , \"epochs\": [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "diagnostic-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = aiqc.Experiment.make(\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_binary\"\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    "    , splitset_id = splitset.id\n",
    "    , repeat_count = 2\n",
    "    , hide_test = False\n",
    "    , hyperparameters = hyperparameters\n",
    "    \n",
    "    , fn_lose = None #automated\n",
    "    , fn_optimize = None #automated\n",
    "    , fn_predict = None #automated\n",
    "    , foldset_id = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ordered-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:09<00:00, 32.27s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-isolation",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Visualization & Metrics](visualization.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-distance",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-president",
   "metadata": {},
   "source": [
    "## b) Low-Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "republican-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('epilepsy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patent-venture",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_df = df[['seizure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fleet-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ndarray3D = df.drop(columns=['seizure']).to_numpy().reshape(1000,178,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ordinary-garden",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_tabular = aiqc.Dataset.Tabular.from_pandas(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "charged-pickup",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = dataset_tabular.make_label(columns='seizure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hawaiian-spectacular",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Validating Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 761493.10it/s]\n",
      "‚è±Ô∏è Ingesting Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:09<00:00, 110.77it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_sequence = aiqc.Dataset.Sequence.from_numpy(ndarray_3D=seq_ndarray3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "clear-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset_sequence.make_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "amateur-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = feature.make_encoderset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "communist-nowhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['0']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoderset = encoderset.make_featurecoder(\n",
    "    sklearn_preprocess = StandardScaler()\n",
    "    , columns = ['0']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "recovered-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [feature.id]\n",
    "    , label_id = label.id\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "charitable-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        hp['neuron_count']\n",
    "        , input_shape=(features_shape[0], features_shape[1])\n",
    "    ))\n",
    "    model.add(Dense(units=label_shape[0], activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "declared-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss=loser\n",
    "        , optimizer=optimizer\n",
    "        , metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        samples_train['features'], samples_train['labels']\n",
    "        , validation_data = (samples_evaluate['features'], samples_evaluate['labels'])\n",
    "        , verbose = 0\n",
    "        , batch_size = hp['batch_size']\n",
    "        , epochs = hp['epochs']\n",
    "        , callbacks = [History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sublime-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aiqc.Algorithm.make(\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_binary\"\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "average-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"neuron_count\": [25]\n",
    "    , \"batch_size\": [8]\n",
    "    , \"epochs\": [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "polished-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = algorithm.make_hyperparamset(\n",
    "    hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "severe-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = algorithm.make_queue(\n",
    "    splitset_id = splitset.id\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , repeat_count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "unusual-ambassador",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:13<00:00, 33.34s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-australia",
   "metadata": {},
   "source": [
    "Reference [Low-Level API Docs](api_high_level.ipynb) for more information including how to work with non-tabular data and defining optimizers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

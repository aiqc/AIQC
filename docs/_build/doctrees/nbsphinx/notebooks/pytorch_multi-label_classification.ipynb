{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "young-phone",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyTorch: Tabular Classify Multi-Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff8ea6-e9ed-482f-97ed-54042956c9e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Categorizing Plant Species with Multi-Label Classification of Phenotypes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-ministry",
   "metadata": {},
   "source": [
    "![farming](../images/vertical_farming.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f0528-571a-40ad-bd16-797041753d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc\n",
    "from aiqc import datum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-horizontal",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-saskatchewan",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-prison",
   "metadata": {},
   "source": [
    "This data is comprised of:\n",
    "- *Label* = the species of the plant.\n",
    "- *Features* = phenotypes of the plant sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e969c1b-d806-47e2-9d65-450fd6099d8c",
   "metadata": {},
   "source": [
    "Reference [Example Datasets](example_datasets.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alone-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('iris.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "later-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd997cf-303b-4925-b102-13d7bbeffb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchmetrics\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-agent",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-alloy",
   "metadata": {},
   "source": [
    "## a) High-Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-buddy",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information including how to work with non-tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "persistent-affair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) featurecoder filters.\n",
      "\n",
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "\n",
      "=> Done. All feature column(s) have featurecoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitset = aiqc.Pipeline.Tabular.make(\n",
    "    # --- Data source ---\n",
    "    df_or_path = df\n",
    "    , dtype = None\n",
    "\n",
    "    # --- Label preprocessing ---\n",
    "    , label_column = 'species'\n",
    "    , label_interpolater = None\n",
    "    , label_encoder = dict(sklearn_preprocess = OrdinalEncoder())\n",
    "\n",
    "    # --- Feature preprocessing ---\n",
    "    , feature_cols_excluded = 'species'\n",
    "    , feature_interpolaters = None\n",
    "    , feature_window = None\n",
    "    , feature_encoders = dict(\n",
    "        sklearn_preprocess = StandardScaler()\n",
    "        , dtypes = ['float64']\n",
    "    )\n",
    "    , feature_reshape_indices = None\n",
    "\n",
    "    # --- Stratification ---\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12\n",
    "    , fold_count = None\n",
    "    , bin_count = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-picnic",
   "metadata": {},
   "source": [
    "Note that `num_classes` is unique to PyTorch multi-classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dynamic-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, num_classes, **hp):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(features_shape[0], 12),\n",
    "        nn.BatchNorm1d(12,12),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "\n",
    "        nn.Linear(12, num_classes),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accomplished-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    ## --- Prepare mini batches for analysis ---\n",
    "    batched_features, batched_labels = aiqc.torch_batcher(\n",
    "        samples_train['features'], samples_train['labels'],\n",
    "        batch_size=hp['batch_size'], enforce_sameSize=False, allow_1Sample=False\n",
    "    )\n",
    "\n",
    "    ## --- Metrics ---\n",
    "    acc = torchmetrics.Accuracy()\n",
    "    # Modeled after `keras.model.History.history` object.\n",
    "    history = {\n",
    "        'loss':list(), 'accuracy': list(), \n",
    "        'val_loss':list(), 'val_accuracy':list()\n",
    "    }\n",
    "\n",
    "    ## --- Training loop ---\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        # --- Batch training ---\n",
    "        for i, batch in enumerate(batched_features):      \n",
    "            # Make raw (unlabeled) predictions.\n",
    "            batch_probability = model(batched_features[i])\n",
    "            batch_flat_labels = batched_labels[i].flatten().to(torch.long)\n",
    "            batch_loss = loser(batch_probability, batch_flat_labels)\n",
    "            # Backpropagation.\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        ## --- Epoch metrics ---\n",
    "        # Overall performance on training data.\n",
    "        train_probability = model(samples_train['features'])\n",
    "        train_flat_labels = samples_train['labels'].flatten().to(torch.long)\n",
    "        train_loss = loser(train_probability, train_flat_labels)\n",
    "        train_acc = acc(train_probability, samples_train['labels'].to(torch.short))\n",
    "        history['loss'].append(float(train_loss))\n",
    "        history['accuracy'].append(float(train_acc))\n",
    "        # Performance on evaluation data.\n",
    "        eval_probability = model(samples_evaluate['features'])\n",
    "        eval_flat_labels = samples_evaluate['labels'].flatten().to(torch.long)\n",
    "        eval_loss = loser(eval_probability, eval_flat_labels)\n",
    "        eval_acc = acc(eval_probability, samples_evaluate['labels'].to(torch.short))    \n",
    "        history['val_loss'].append(float(eval_loss))\n",
    "        history['val_accuracy'].append(float(eval_acc))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-research",
   "metadata": {},
   "source": [
    "Optional, will be automatically selected based on `analysis_type` if left as `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collect-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_lose(**hp):\n",
    "\tloser = nn.CrossEntropyLoss(reduction=hp['reduction'])\n",
    "\treturn loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strong-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"reduction\": ['mean', 'sum']\n",
    "    , \"batch_size\": [3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "particular-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = aiqc.Experiment.make(\n",
    "    # --- Analysis type ---\n",
    "    library = \"pytorch\"\n",
    "    , analysis_type = \"classification_multi\"\n",
    "    \n",
    "    # --- Model functions ---\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    "    , fn_lose = None #auto\n",
    "    , fn_optimize = None #auto\n",
    "    , fn_predict = None #auto    \n",
    "    \n",
    "    # --- Training options ---\n",
    "    , repeat_count = 1\n",
    "    , hyperparameters = hyperparameters\n",
    "    , pick_percent = None\n",
    "    \n",
    "    # --- Data source ---\n",
    "    , splitset_id = splitset.id\n",
    "    , foldset_id = None\n",
    "    , hide_test = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mechanical-graduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ”® Training Models ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  3.66s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-norfolk",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Visualization & Metrics](visualization.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-remains",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-criterion",
   "metadata": {},
   "source": [
    "## b) Low-Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-funeral",
   "metadata": {},
   "source": [
    "Reference [Low-Level API Docs](api_low_level.ipynb) for more information including how to work with non-tabular data, and defining an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ordinary-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_optimize(**hp):\n",
    "    optimizer = keras.optimizers.Adamax()\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dirty-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = aiqc.Dataset.Tabular.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "funded-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 'species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "educational-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.make_label(columns=[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "taken-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcoder = label.make_labelcoder(\n",
    "    sklearn_preprocess = OrdinalEncoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "earlier-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset.make_feature(exclude_columns=[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "typical-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = feature.make_encoderset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "agricultural-escape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) featurecoder filters.\n",
      "\n",
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "\n",
      "=> Done. All feature column(s) have featurecoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurecoder_0 = encoderset.make_featurecoder(\n",
    "    sklearn_preprocess = PowerTransformer(method='yeo-johnson', copy=False)\n",
    "    , dtypes = ['float64']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "demographic-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [feature.id]\n",
    "    , label_id = label.id\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-mining",
   "metadata": {},
   "source": [
    "Note that `num_classes` is unique to PyTorch multi-classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "previous-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, num_classes, **hp):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(features_shape[0], 12),\n",
    "        nn.BatchNorm1d(12,12),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "\n",
    "        nn.Linear(12, num_classes),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "major-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    ## --- Prepare mini batches for analysis ---\n",
    "    batched_features, batched_labels = aiqc.torch_batcher(\n",
    "        samples_train['features'], samples_train['labels'],\n",
    "        batch_size=hp['batch_size'], enforce_sameSize=False, allow_1Sample=False\n",
    "    )\n",
    "\n",
    "    ## --- Metrics ---\n",
    "    acc = torchmetrics.Accuracy()\n",
    "    # Modeled after `keras.model.History.history` object.\n",
    "    history = {\n",
    "        'loss':list(), 'accuracy': list(), \n",
    "        'val_loss':list(), 'val_accuracy':list()\n",
    "    }\n",
    "\n",
    "    ## --- Training loop ---\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        # --- Batch training ---\n",
    "        for i, batch in enumerate(batched_features):      \n",
    "            # Make raw (unlabeled) predictions.\n",
    "            batch_probability = model(batched_features[i])\n",
    "            batch_flat_labels = batched_labels[i].flatten().to(torch.long)\n",
    "            batch_loss = loser(batch_probability, batch_flat_labels)\n",
    "            # Backpropagation.\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        ## --- Epoch metrics ---\n",
    "        # Overall performance on training data.\n",
    "        train_probability = model(samples_train['features'])\n",
    "        train_flat_labels = samples_train['labels'].flatten().to(torch.long)\n",
    "        train_loss = loser(train_probability, train_flat_labels)\n",
    "        train_acc = acc(train_probability, samples_train['labels'].to(torch.short))\n",
    "        history['loss'].append(float(train_loss))\n",
    "        history['accuracy'].append(float(train_acc))\n",
    "        # Performance on evaluation data.\n",
    "        eval_probability = model(samples_evaluate['features'])\n",
    "        eval_flat_labels = samples_evaluate['labels'].flatten().to(torch.long)\n",
    "        eval_loss = loser(eval_probability, eval_flat_labels)\n",
    "        eval_acc = acc(eval_probability, samples_evaluate['labels'].to(torch.short))    \n",
    "        history['val_loss'].append(float(eval_loss))\n",
    "        history['val_accuracy'].append(float(eval_acc))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-halloween",
   "metadata": {},
   "source": [
    "Optional, will be automatically selected based on `analysis_type` if left as `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "southeast-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_lose(**hp):\n",
    "\tloser = nn.CrossEntropyLoss(reduction=hp['reduction'])\n",
    "\treturn loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stopped-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"reduction\": ['mean', 'sum']\n",
    "    , \"batch_size\": [3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alleged-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aiqc.Algorithm.make(\n",
    "    library = \"pytorch\"\n",
    "    , analysis_type = \"classification_multi\"\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "endangered-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = algorithm.make_hyperparamset(\n",
    "    hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "another-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = algorithm.make_queue(\n",
    "    splitset_id = splitset.id\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , repeat_count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ambient-recipe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ”® Training Models ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-square",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Visualization & Metrics](visualization.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f97666b-0c52-428d-ad3e-7763e4093e6f",
   "metadata": {},
   "source": [
    "# Feature Importance for Drug Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1508d-9a38-4e8f-bb52-c2d523878c17",
   "metadata": {},
   "source": [
    "*In silico interpretation of compound selection using permuted feature importance of neural networks to rank High Throughput Screening (HTS) criteria, and identify 2 compounds (out of 57,546) with 95% confidence of target activation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a553c-a6ba-4e42-b565-0c35b2fc4ea4",
   "metadata": {},
   "source": [
    "![docking](../../../_static/images/banner/drugs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32dca02-47bc-402b-9f01-17396f302cb1",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79b4a0-b267-40fc-84ba-b620f6d8f76d",
   "metadata": {},
   "source": [
    "This dataset is comprised of:\n",
    "\n",
    "* *Features* - 155 structural screening criteria for each compound.\n",
    "* *Labels* - whether or not the MAPK target is activated or inactivated by the compound.\n",
    "\n",
    "> *Source:* PubChem Bioassay from Scripps Research Institute Molecular Screening Center. \n",
    "> https://archive.ics.uci.edu/ml/datasets/PubChem+Bioassay+Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa1d76-3236-47e0-92b9-34616c3a8a47",
   "metadata": {},
   "source": [
    "The purpose of this analysis is to use *permuted feature importance* to understand which chemical structures are driving the activation of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ed4694c9-bfdf-4eb3-9702-2bb73494a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc.orm import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "99dd9ba2-af05-4455-84f3-01b14edf5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"MAPK_bioassay.parquet\")\n",
    "shared_dataset = Dataset.Tabular.from_pandas(dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cebc53-c488-488d-805b-aa88ce10ba7c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30beb5e6-96d6-490d-aa5b-db298c626e91",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926fd53e-c6bb-4124-a858-45e7afc34aa3",
   "metadata": {},
   "source": [
    "Since we have so many columns, we will examine their variation en masse in order to determine how we want to encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0655a530-2eae-4c89-9631-c79a28d8e25b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Features = 123 \n",
      "Non-binary Features = 31 \n"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove('Outcome')\n",
    "\n",
    "features_binary = []\n",
    "features_nonbinary = []\n",
    "\n",
    "for col in features:\n",
    "    values = len(df[col].value_counts().tolist())\n",
    "    if (values == 1):\n",
    "        pass #no variation\n",
    "    elif (values == 2):\n",
    "        features_binary.append(col)\n",
    "    else:\n",
    "        # None appeared ordinal.\n",
    "        features_nonbinary.append(col)\n",
    "        \n",
    "print(f\"Binary Features = {len(features_binary)} \")\n",
    "print(f\"Non-binary Features = {len(features_nonbinary)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed3e12-fe5b-4d88-bd61-a288a1cfdf11",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3aa073-dcfa-400b-8df0-22a80cae08ae",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10cada-4658-4f7f-acdd-580f0697a6cb",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa91176-8ec9-49bc-aee1-0ec9f207047a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aiqc.mlops import Pipeline, Input, Target, Stratifier\n",
    "from sklearn.preprocessing import LabelBinarizer, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8e4f2-9d52-423e-92f7-b9b49377d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    Input(\n",
    "        dataset = shared_dataset,\n",
    "        encoder = [\n",
    "            Input.Encoder(OrdinalEncoder(), columns=features_binary),\n",
    "            Input.Encoder(StandardScaler(), columns=features_nonbinary)\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    Target(\n",
    "        dataset   = shared_dataset\n",
    "        , column  = 'Outcome'\n",
    "        , encoder = Target.Encoder(LabelBinarizer())\n",
    "    ),\n",
    "    \n",
    "    Stratifier(size_test=0.26)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb2f27-07ff-4063-8caa-da9abe162d98",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618aadad-c255-4c0d-8eb6-00910fd5d1c1",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc794b6-c8b6-4cc6-aa5c-fecd2ead2ce3",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0454f37a-5e9b-4e61-aa3e-5aa62a2f7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc.mlops import Experiment, Architecture, Trainer\n",
    "from aiqc.utils.tensorflow import TrainingCallback\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "878a9741-951a-45ea-96c9-5c96e0d3d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):\n",
    "    m = tf.keras.models.Sequential()\n",
    "    m.add(l.Input(shape=features_shape))\n",
    "    \n",
    "    # First hidden layer.\n",
    "    m.add(l.Dense(hp['first_neurons'], kernel_initializer=hp['init']))\n",
    "    m.add(l.BatchNormalization())\n",
    "    m.add(l.Activation(hp['activation']))\n",
    "    m.add(l.Dropout(hp['drop_rate']))\n",
    "    \n",
    "    # Second hidden layer.\n",
    "    if (hp['second_layer']==True):\n",
    "        m.add(l.Dense(hp['after_neurons'], kernel_initializer=hp['init']))\n",
    "        m.add(l.BatchNormalization())\n",
    "        m.add(l.Activation(hp['activation']))\n",
    "        m.add(l.Dropout(hp['drop_rate']))\n",
    "        \n",
    "        if (hp['third_layer']==True):\n",
    "            m.add(l.Dense(hp['after_neurons'], kernel_initializer=hp['init']))\n",
    "            m.add(l.BatchNormalization())\n",
    "            m.add(l.Activation(hp['activation']))\n",
    "            m.add(l.Dropout(hp['drop_rate']))\n",
    "        \n",
    "            if (hp['fourth_layer']==True):\n",
    "                m.add(l.Dense(hp['after_neurons'], kernel_initializer=hp['init']))\n",
    "                m.add(l.BatchNormalization())\n",
    "                m.add(l.Activation(hp['activation']))\n",
    "                m.add(l.Dropout(hp['drop_rate']))\n",
    "    \n",
    "    # Output layer\n",
    "    m.add(l.Dense(units=label_shape[0], activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acf1892f-6d6f-481e-8672-4796d5c345fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(\n",
    "    model, loser, optimizer,\n",
    "    train_features, train_label,\n",
    "    eval_features, eval_label,\n",
    "    **hp\n",
    "):\n",
    "    model.compile(\n",
    "        loss        = loser\n",
    "        , optimizer = optimizer\n",
    "        , metrics   = ['accuracy', tf.keras.metrics.Precision()]\n",
    "    )\n",
    "    \n",
    "    # Early stopping.\n",
    "    metric_cuttoffs = [\n",
    "        {\"metric\":\"val_precision\", \"cutoff\":0.75, \"above_or_below\":\"above\"},\n",
    "    ]\n",
    "    cutoffs = TrainingCallback.MetricCutoff(metric_cuttoffs)\n",
    "    \n",
    "    model.fit(\n",
    "        train_features, train_label\n",
    "        , validation_data = (eval_features, eval_label)\n",
    "        , verbose         = 0\n",
    "        , batch_size      = hp['batch_size']\n",
    "        , epochs          = hp['epochs']\n",
    "        , callbacks       = [tf.keras.callbacks.History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dd164f9-225a-4f21-8ced-73e0b9f28794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_lose(**hp):\n",
    "    if (hp['loss_imbalanced']==True):\n",
    "        loser = tf.keras.losses.BinaryFocalCrossentropy(gamma=hp['gamma'], from_logits=False)\n",
    "    else:\n",
    "        loser = tf.keras.losses.BinaryCrossentropy()\n",
    "    return loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0acd0b8-a063-4ff8-87c9-866dcb70a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_optimize(**hp):\n",
    "    optimizer = tf.keras.optimizers.Adamax(hp['learning_rate'])\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0dc1d216-08fa-4797-97ae-366748d1987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(\n",
    "    first_neurons     = [120]\n",
    "    , after_neurons   = [12]\n",
    "    , second_layer    = [True, False]\n",
    "    , third_layer     = [False]\n",
    "    , fourth_layer    = [False]\n",
    "    , activation      = ['relu']\n",
    "    , init            = ['he_uniform']\n",
    "    , epochs          = [20]\n",
    "    , batch_size      = [5]\n",
    "    , drop_rate       = [0.4]\n",
    "    , gamma           = [1.0]\n",
    "    , loss_imbalanced = [True, False]\n",
    "    , learning_rate   = [0.01]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc4783fe-3d97-4f0b-827a-625a94b8958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = Experiment(\n",
    "    Architecture(\n",
    "        library           = \"keras\"\n",
    "        , analysis_type   = \"classification_binary\"\n",
    "        , fn_build        = fn_build\n",
    "        , fn_train        = fn_train\n",
    "        , fn_optimize     = fn_optimize\n",
    "        , hyperparameters = hyperparameters\n",
    "    ),\n",
    "    \n",
    "    Trainer(\n",
    "        pipeline        = pipeline\n",
    "        , repeat_count  = 2\n",
    "        , repeat_count  = 3\n",
    "        , permute_count = 7\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4aba8eed-4edc-4ff6-a542-7f51f34ff434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ”® Training Models ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [07:44<00:00, 38.74s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65957db-9207-4f41-9365-ca86ff5866d7",
   "metadata": {},
   "source": [
    "Now normally, I would say that these models are too overfit to be usable, but remember that we are interested in the features that drive active compound prediction. The fact that these models perform so similarly indicates that the signal coming from the features is strong, which is what we want. There is something there and we'll use feature importance to find out what that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "56321445-c185-48c8-9ecd-11f16ed9d169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparamcombo_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>repeat_index</th>\n",
       "      <th>predictor_id</th>\n",
       "      <th>split</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>4</td>\n",
       "      <td>662</td>\n",
       "      <td>train</td>\n",
       "      <td>0.864569</td>\n",
       "      <td>0.831579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>6</td>\n",
       "      <td>664</td>\n",
       "      <td>train</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.802956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>5</td>\n",
       "      <td>663</td>\n",
       "      <td>train</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.849582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>658</td>\n",
       "      <td>train</td>\n",
       "      <td>0.856390</td>\n",
       "      <td>0.796569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>11</td>\n",
       "      <td>669</td>\n",
       "      <td>train</td>\n",
       "      <td>0.855989</td>\n",
       "      <td>0.811224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>7</td>\n",
       "      <td>665</td>\n",
       "      <td>train</td>\n",
       "      <td>0.855153</td>\n",
       "      <td>0.836512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>9</td>\n",
       "      <td>667</td>\n",
       "      <td>train</td>\n",
       "      <td>0.853521</td>\n",
       "      <td>0.844011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>8</td>\n",
       "      <td>666</td>\n",
       "      <td>train</td>\n",
       "      <td>0.852735</td>\n",
       "      <td>0.839779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>659</td>\n",
       "      <td>train</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.866469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "      <td>660</td>\n",
       "      <td>train</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>0.894231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>10</td>\n",
       "      <td>668</td>\n",
       "      <td>train</td>\n",
       "      <td>0.837274</td>\n",
       "      <td>0.817935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>661</td>\n",
       "      <td>train</td>\n",
       "      <td>0.800628</td>\n",
       "      <td>0.891608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>6</td>\n",
       "      <td>664</td>\n",
       "      <td>test</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.717557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>10</td>\n",
       "      <td>668</td>\n",
       "      <td>test</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>8</td>\n",
       "      <td>666</td>\n",
       "      <td>test</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.735537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>11</td>\n",
       "      <td>669</td>\n",
       "      <td>test</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>658</td>\n",
       "      <td>test</td>\n",
       "      <td>0.720307</td>\n",
       "      <td>0.686131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>7</td>\n",
       "      <td>665</td>\n",
       "      <td>test</td>\n",
       "      <td>0.712551</td>\n",
       "      <td>0.715447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>4</td>\n",
       "      <td>662</td>\n",
       "      <td>test</td>\n",
       "      <td>0.711462</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>9</td>\n",
       "      <td>667</td>\n",
       "      <td>test</td>\n",
       "      <td>0.694561</td>\n",
       "      <td>0.721739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "      <td>660</td>\n",
       "      <td>test</td>\n",
       "      <td>0.681223</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>5</td>\n",
       "      <td>663</td>\n",
       "      <td>test</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.691667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>659</td>\n",
       "      <td>test</td>\n",
       "      <td>0.678112</td>\n",
       "      <td>0.724771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>661</td>\n",
       "      <td>test</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hyperparamcombo_id  job_id  repeat_index  predictor_id  split        f1  \\\n",
       "8                  237     237             4           662  train  0.864569   \n",
       "12                 237     237             6           664  train  0.861295   \n",
       "10                 237     237             5           663  train  0.859155   \n",
       "0                  237     237             0           658  train  0.856390   \n",
       "22                 237     237            11           669  train  0.855989   \n",
       "14                 237     237             7           665  train  0.855153   \n",
       "18                 237     237             9           667  train  0.853521   \n",
       "16                 237     237             8           666  train  0.852735   \n",
       "2                  237     237             1           659  train  0.848837   \n",
       "4                  237     237             2           660  train  0.841629   \n",
       "20                 237     237            10           668  train  0.837274   \n",
       "6                  237     237             3           661  train  0.800628   \n",
       "13                 237     237             6           664   test  0.737255   \n",
       "21                 237     237            10           668   test  0.726562   \n",
       "17                 237     237             8           666   test  0.726531   \n",
       "23                 237     237            11           669   test  0.724528   \n",
       "1                  237     237             0           658   test  0.720307   \n",
       "15                 237     237             7           665   test  0.712551   \n",
       "9                  237     237             4           662   test  0.711462   \n",
       "19                 237     237             9           667   test  0.694561   \n",
       "5                  237     237             2           660   test  0.681223   \n",
       "11                 237     237             5           663   test  0.680328   \n",
       "3                  237     237             1           659   test  0.678112   \n",
       "7                  237     237             3           661   test  0.666667   \n",
       "\n",
       "    precision  \n",
       "8    0.831579  \n",
       "12   0.802956  \n",
       "10   0.849582  \n",
       "0    0.796569  \n",
       "22   0.811224  \n",
       "14   0.836512  \n",
       "18   0.844011  \n",
       "16   0.839779  \n",
       "2    0.866469  \n",
       "4    0.894231  \n",
       "20   0.817935  \n",
       "6    0.891608  \n",
       "13   0.717557  \n",
       "21   0.704545  \n",
       "17   0.735537  \n",
       "23   0.680851  \n",
       "1    0.686131  \n",
       "15   0.715447  \n",
       "9    0.697674  \n",
       "19   0.721739  \n",
       "5    0.742857  \n",
       "11   0.691667  \n",
       "3    0.724771  \n",
       "7    0.782609  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.metrics_to_pandas(\n",
    "    selected_metrics = ['f1','precision']\n",
    "    , sort_by        = 'f1'\n",
    "    , ascending      = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0f200882-c306-4def-a567-285fe7e27fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 666\n",
    "predictor = aiqc.Predictor.get_by_id(id)\n",
    "prediction = predictor.predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f09808-94d5-41d1-8745-e7b16a8b57fd",
   "metadata": {},
   "source": [
    "It's not perfect, but overall we are observing the predictive pattern that we want from this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b65881-85dd-42a8-b6b9-4cb650fa88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82c002-f2c1-4c27-b73e-6886d9ec580e",
   "metadata": {},
   "source": [
    "![matrixTrain](../../../_static/images/notebook/docking_matrix_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed34a57-33ba-4010-9886-e75d47e4a891",
   "metadata": {},
   "source": [
    "![matrixTest](../../../_static/images/notebook/docking_matrix_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0816af-9a0e-491e-851c-704561a3d1a7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417b0c2-67d0-44fa-a19b-f421f456e4f5",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffd7c9-41e5-4394-be2b-c7c8e8f78d8f",
   "metadata": {},
   "source": [
    "The `Experiment.permute_count` parameter determines how many times each feature is permuted and run back through the model. The median difference in loss is then compared to the baseline loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e5f1c-4fd6-4c62-bac9-976d1df3bde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction.plot_feature_importance(height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687372a-dea4-4c89-a90b-8a930931bc0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "![dockingFeatures](../../../_static/images/notebook/docking_features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0e4bf-1f53-482f-a40c-8122531b9a97",
   "metadata": {},
   "source": [
    "In comparison to traditional statistics, the heuristics of deep learning help us quantify the impact of subtle variation within the dataset.\n",
    "\n",
    "* *Box plots* appeared nearly identical.\n",
    "* *T-tests* did not rule all of these features to be significant. \n",
    " \n",
    "Despite this, our model is able to achieve `f1=0.726` and `precision=0.735`, which can help us rule out/in tens of thousands of future compounds. This suggests that the model is able to detect not only variation within a feature, but also interaction between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96dd52-1331-4116-86c2-fa6c7f52dbfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "active = df[df['Outcome']=='Active']\n",
    "inactive = df[df['Outcome']=='Inactive']\n",
    "top_6 = ['NumHBD','NumRot','WBN_LP_L_0.25','HBA_05_ARC','WBN_LP_H_1.00','WBN_EN_H_1.00']\n",
    "\n",
    "for col in top_6:\n",
    "    ttest_sig = ttest_ind(active[col], inactive[col])[1]<0.05\n",
    "    px.box(df, x=\"Outcome\", y=col, title=f\"Significant P-value: {ttest_sig}\", height=50).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd381d5f-d3c6-41b9-be6e-8824a8c7f272",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "![boxFalse](../../../_static/images/notebook/box_plot_false.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e9357-1b5e-464d-b516-28a07f3d631d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "![boxTrue](../../../_static/images/notebook/box_plot_true.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb6d46-f300-486a-8ca0-1ab86dc99800",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, our model enables us to determine which compounds most strongly fit these patterns based on the probability of their prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "9fdce181-ad9c-4ffb-bca8-302a2cad9fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Compound_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Active</td>\n",
       "      <td>0.977319</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Active</td>\n",
       "      <td>0.964854</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outcome  Probability  Compound_ID\n",
       "113  Active     0.977319          113\n",
       "174  Active     0.964854          174"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for split in ['train','test']:\n",
    "    sample_ids = splitset.samples[split]\n",
    "    sample_probabilities = prediction.probabilities[split]\n",
    "\n",
    "    samples = splitset.label.to_pandas(samples=sample_ids)\n",
    "    samples['Probability'] = sample_probabilities\n",
    "    samples['Compound_ID'] = sample_ids\n",
    "    \n",
    "    samples = samples[samples['Probability'] >= 0.95]\n",
    "    samples = samples[samples['Outcome'] == 'Active']\n",
    "    dfs.append(samples)\n",
    "pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c462f24f-9c35-4326-acd6-c29aa9c7cac0",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Across our entire dataset of 57,546 compounds, only 2 compounds exhibit over 95% probability of being active. If we trust the scientific relevance of these features, then these compounds are great candidates for the next phase.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa255b3-2c4e-447a-b07a-eb4e40eb1513",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e6d9b-b23a-4016-84cc-2f40276e8d41",
   "metadata": {},
   "source": [
    "## Visualization & Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d81b9-c845-4d6e-90f0-385951287f07",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Dashboard](dashboard.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "operating-concept",
   "metadata": {},
   "source": [
    "# Heterogeneous/ Multi-Modal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-subject",
   "metadata": {},
   "source": [
    "*Binary Classification of Galaxy Morphologies Using Images Paired with Tabular Metadata.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-dollar",
   "metadata": {},
   "source": [
    "![bannerGalaxy](../images/banner_galaxy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-noise",
   "metadata": {},
   "source": [
    "Mixed data analysis is one of the areas where deep learning really sets itself apart from traditional statistics and machine learning. Neural networks are an effective way to logically encode and combine any type of data (image, text, time series, audio, tabular spreadsheets, video, etc) all-the-while converging toward the minimization a single *loss* metric. This leads to rich experiments that resemble real-world scenarios; aka man-machine symbiosis. For example, consider combining a doctor's diagnosis notes with electronic medical records and histology imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-venue",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-tuner",
   "metadata": {},
   "source": [
    "*This is an advanced example put together for a demo that builds upon the documentation of the Low-Level API and the example workflows for binary classification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wrapped-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "%capture\n",
    "aiqc.setup()\n",
    "aiqc.destroy_db(confirm=True, rebuild=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-helen",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-click",
   "metadata": {},
   "source": [
    "## Ingesting Example Galaxy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-clinton",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "european-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc import datum\n",
    "df = datum.to_pandas('galaxies.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-police",
   "metadata": {},
   "source": [
    "Using the built-in structured data about 40 galaxies, we'll derive:\n",
    "\n",
    "- A binary, categorical label: `morphology`.\n",
    "- Categorical and numeric metadata features: `clarity`, `angle`.\n",
    "- A manifest detailing where to find our image files: `url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "capital-camcorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morphology</th>\n",
       "      <th>clarity</th>\n",
       "      <th>angle</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bar</td>\n",
       "      <td>0</td>\n",
       "      <td>face</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>3</td>\n",
       "      <td>angle</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bar</td>\n",
       "      <td>3</td>\n",
       "      <td>face</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  morphology  clarity  angle  \\\n",
       "0        bar        0   face   \n",
       "1        bar        3  angle   \n",
       "2        bar        3   face   \n",
       "\n",
       "                                                 url  \n",
       "0  https://raw.githubusercontent.com/aiqc/aiqc/ma...  \n",
       "1  https://raw.githubusercontent.com/aiqc/aiqc/ma...  \n",
       "2  https://raw.githubusercontent.com/aiqc/aiqc/ma...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-attribute",
   "metadata": {},
   "source": [
    "From a single `Dataset.Tabular` we'll specify a `Label` and `Feature` before encoding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dried-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tab = aiqc.Dataset.Tabular.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "outdoor-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset_tab.make_label(columns=['morphology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "extended-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "transsexual-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labelcoder: 1>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.make_labelcoder(sklearn_preprocess=OrdinalEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "angry-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tab = dataset_tab.make_feature(exclude_columns=['morphology','url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "theoretical-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = feature_tab.make_encoderset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tropical-terrorism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['clarity']\n",
      "\n",
      "=> The remaining column(s) and dtype(s) can be used in downstream Featurecoder(s):\n",
      "{'angle': 'object'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Featurecoder: 1>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderset.make_featurecoder(\n",
    "    sklearn_preprocess = StandardScaler(),\n",
    "    columns = ['clarity']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "electoral-barrel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 1 \\_________\n",
      "\n",
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.sparse=False`.\n",
      "   This would have generated 'scipy.sparse.csr.csr_matrix', causing Keras training to fail.\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['angle']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Featurecoder: 2>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderset.make_featurecoder(\n",
    "    sklearn_preprocess = OneHotEncoder(),\n",
    "    columns = ['angle']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-gilbert",
   "metadata": {},
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-restriction",
   "metadata": {},
   "source": [
    "Construct a `Dataset.Image` from that manifest and use it as a 2nd `Feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "satisfactory-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = df['url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beginning-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Validating Images üñºÔ∏è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:04<00:00,  9.09it/s]\n",
      "üñºÔ∏è Ingesting Images üñºÔ∏è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:04<00:00,  8.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_img = aiqc.Dataset.Image.from_urls(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "silent-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_images = aiqc.Dataset.Image.to_pillow(id=dataset_img.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-internet",
   "metadata": {},
   "source": [
    "**Bar galaxies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bridal-charity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=110x80 at 0x17DB80820>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_images[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "great-indication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=110x80 at 0x17E01FE20>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-elite",
   "metadata": {},
   "source": [
    "Although it is easy enough to distinguish between the two types with the naked eye, you start to realize that a *bar* galaxy is almost like a degraded *spiral* galaxy. Like anything else, there is a gray area in whether or not the band of stars/ rectangle of light connecting the two main galactic arms is to be considered a \"bar\" or more of an oval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-liquid",
   "metadata": {},
   "source": [
    "**Spiral galaxies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "tropical-chancellor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=110x80 at 0x17D5AD1C0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_images[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "sweet-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=110x80 at 0x17D5AD3A0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_images[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "opened-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_img = dataset_img.make_feature()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-pharmacology",
   "metadata": {},
   "source": [
    "We have only 40 samples, so we'll keep our validation and test *splits* on the smaller size, and definitely forgo cross-validation.\n",
    "\n",
    "Notice how we pass in both the *tabular* and *image* Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "tutorial-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [feature_tab.id, feature_img.id]\n",
    "\t, label_id = label.id\n",
    "    , size_validation = 0.125\n",
    "\t, size_test = 0.175\n",
    "    , fold_count = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-charm",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-transcript",
   "metadata": {},
   "source": [
    "## Defining a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-buffer",
   "metadata": {},
   "source": [
    "AIQC makes it easy to compartmentalize both Keras/TensorFlow and PyTorch models. See `Algorithm` in the Low-Level API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ordinary-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-church",
   "metadata": {},
   "source": [
    "Hyperparameters are passed in as the `hp**` *kwargs*, which allows you to tweak both the topology and the params alike.\n",
    "\n",
    "Below we see two towers, feedforward and convolutional, that are eventually concatenated together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "light-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(feature_shapes, label_shape, **hp):\n",
    "    \n",
    "    # Feed forward tower using the first Feature.\n",
    "    ff_input = layers.Input(shape=feature_shapes[0][0])    \n",
    "    ff = layers.Dense(units=hp['ff_neurons'], activation='relu')(ff_input)\n",
    "    ff = layers.Dropout(0.2)(ff)\n",
    "    model_ff = Model(ff_input, ff)\n",
    "        \n",
    "    # Convolutional tower using the second Feature.\n",
    "    cnn_input = layers.Input(shape=feature_shapes[1])\n",
    "    cnn = layers.Conv1D(\n",
    "        16*hp['cnn_multiply'], kernel_size=3,\n",
    "        padding='same', activation='relu',\n",
    "        kernel_initializer=hp['init'])(cnn_input)\n",
    "    #cnn = layers.MaxPooling1D(pool_size=2)(cnn)\n",
    "    cnn = layers.BatchNormalization()(cnn)\n",
    "    cnn = layers.Dropout(hp['dropout'])(cnn)\n",
    "    \n",
    "    cnn = layers.Conv1D(\n",
    "        16*hp['cnn_multiply'], kernel_size=3,\n",
    "        padding='same', activation='relu',\n",
    "        kernel_initializer=hp['init'])(cnn)\n",
    "    #cnn = layers.MaxPooling1D(pool_size=2)(cnn)\n",
    "    cnn = layers.BatchNormalization()(cnn)\n",
    "    cnn = layers.Dropout(hp['dropout'])(cnn)\n",
    "    \n",
    "    cnn = layers.Conv1D(\n",
    "        32*hp['cnn_multiply'], kernel_size=3,\n",
    "        padding='same', activation='relu',\n",
    "        kernel_initializer=hp['init'])(cnn)\n",
    "    #cnn = layers.MaxPooling1D(pool_size=2)(cnn)\n",
    "    cnn = layers.BatchNormalization()(cnn)\n",
    "    cnn = layers.Dropout(hp['dropout'])(cnn)\n",
    "    \n",
    "    if ('4th_cnn' == True):\n",
    "        cnn = layers.Conv1D(\n",
    "            32*hp['cnn_multiply'], kernel_size=3,\n",
    "            padding='same', activation='relu',\n",
    "            kernel_initializer=hp['init'])(cnn)\n",
    "        #cnn = layers.MaxPooling1D(pool_size=2)(cnn)\n",
    "        cnn = layers.BatchNormalization()(cnn)\n",
    "        cnn = layers.Dropout(hp['dropout'])(cnn)\n",
    "\n",
    "    # Perform one dense layer on CNN output, so that the tabular data\n",
    "    # can talk directly to the \n",
    "    cnn = layers.Flatten()(cnn)\n",
    "    cnn = layers.BatchNormalization()(cnn)\n",
    "    cnn = layers.Activation('relu')(cnn)\n",
    "    cnn = layers.Dropout(0.2)(cnn)\n",
    "    model_cnn = Model(cnn_input, cnn)\n",
    "\n",
    "    concat = layers.concatenate([model_ff.output, model_cnn.output])\n",
    "    join = layers.Dense(hp['concat_neurons'], activation='relu')(concat)\n",
    "    join = layers.BatchNormalization()(join)\n",
    "    join = layers.Activation('relu')(join)\n",
    "    join = layers.Dropout(0.2)(join)\n",
    "    \n",
    "    join = layers.Dense(label_shape[0], activation='sigmoid')(join)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=[model_ff.input, model_cnn.input], outputs=join)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "democratic-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss = loser\n",
    "        , optimizer = optimizer\n",
    "        , metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Early stopper.\n",
    "    metrics_cuttoffs = [\n",
    "        {\"metric\":\"accuracy\", \"cutoff\":0.90, \"above_or_below\":\"above\"},\n",
    "        {\"metric\":\"val_accuracy\", \"cutoff\":0.80, \"above_or_below\":\"above\"}, #5 samples in validation set.\n",
    "    ]\n",
    "    cutoffs = aiqc.TrainingCallback.Keras.MetricCutoff(metrics_cuttoffs)\n",
    "    callbacks=[keras.callbacks.History(), cutoffs]    \n",
    "        \n",
    "        \n",
    "    model.fit(\n",
    "        x = samples_train[\"features\"]\n",
    "        , y = samples_train[\"labels\"]\n",
    "        , validation_data = (\n",
    "            samples_evaluate[\"features\"]\n",
    "            , samples_evaluate[\"labels\"]\n",
    "        )\n",
    "        , verbose = 0\n",
    "        , batch_size = hp['batch_size']\n",
    "        , epochs = hp['epoch_count']\n",
    "        , callbacks=callbacks\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-triumph",
   "metadata": {},
   "source": [
    "You can also customize the functions for loss, optimization, and prediction - but we'll just run with the defaults for binary classification analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "imperial-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aiqc.Algorithm.make(\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_binary\"\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    "    \n",
    "    , fn_lose = None\n",
    "    , fn_optimize = None\n",
    "    , fn_predict = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-acrobat",
   "metadata": {},
   "source": [
    "Define the params that will be passed in as the `hp**` argument in the functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "negative-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epoch_count\": [300]\n",
    "    , \"learning_rate\": [0.01]\n",
    "    , \"batch_size\": [5]\n",
    "    \n",
    "    , \"ff_neurons\": [5]\n",
    "\n",
    "    , \"cnn_multiply\": [1.0, 0.5]\n",
    "    , \"dropout\": [0.5]\n",
    "    , \"init\": ['he_normal']\n",
    "    , \"4th_cnn\": [True]\n",
    "    \n",
    "    , \"concat_neurons\": [64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "composed-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = algorithm.make_hyperparamset(\n",
    "    hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-visit",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-qualification",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-antenna",
   "metadata": {},
   "source": [
    "`repeat_count` runs the same model/params multiple times to help rule chance out of [or into] these non-deterministic analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "protective-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = algorithm.make_queue(\n",
    "    splitset_id = splitset.id\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , repeat_count = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "round-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "indoor-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:   0%|                                                 | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #115 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  10%|‚ñà‚ñà‚ñà‚ñà                                     | 1/10 [00:12<01:52, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #167 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 2/10 [00:28<01:54, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #21 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 3/10 [00:32<01:09,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #66 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 4/10 [00:41<00:56,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #138 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 5/10 [00:55<00:55, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #105 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 6/10 [01:06<00:44, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #104 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 7/10 [01:17<00:33, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #167 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 8/10 [01:33<00:25, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #281 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 9/10 [01:59<00:16, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #95 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.9, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.8, 'metric': 'val_accuracy'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:09<00:00, 12.90s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-negative",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-serbia",
   "metadata": {},
   "source": [
    "## Interpret Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-business",
   "metadata": {},
   "source": [
    "The *boomerang* chart shows how each model performed across all of its splits [and or folds]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-jacksonville",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queue.plot_performance(\n",
    "    max_loss = 3.0, min_accuracy = 0.70\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-malaysia",
   "metadata": {
    "tags": []
   },
   "source": [
    "![galaxyBoomerang](../images/galaxy_boomerang.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-sacramento",
   "metadata": {},
   "source": [
    "Let's dig into that green model with precise loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "particular-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = aiqc.Predictor.get_by_id(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "exposed-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epoch_count</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ff_neurons</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn_multiply</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dropout</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>init</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4th_cnn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>concat_neurons</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            param      value\n",
       "0     epoch_count        300\n",
       "1   learning_rate       0.01\n",
       "2      batch_size          5\n",
       "3      ff_neurons          5\n",
       "4    cnn_multiply        1.0\n",
       "5         dropout        0.5\n",
       "6            init  he_normal\n",
       "7         4th_cnn       True\n",
       "8  concat_neurons         64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_hyperparameters(as_pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-upset",
   "metadata": {},
   "source": [
    "Not exactly the smoothest curve, and it seems like we could have learned more with a bit of patience, but, then again, it always seems that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.plot_learning_curve(loss_skip_15pct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-concentrate",
   "metadata": {},
   "source": [
    "![galaxyLearn](../images/galaxy_learn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-copyright",
   "metadata": {},
   "source": [
    "The charts below show how it performed when running predictions against each split in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "gross-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.plot_roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-association",
   "metadata": {},
   "source": [
    "![galaxyRoc](../images/galaxy_roc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-purchase",
   "metadata": {},
   "source": [
    "Interestingly enough, the model is performing poorly on the *training* split. I guess that's what you get when you set `dropout=0.5`. You can tell that it hasn't learned all of the spiral patterns yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-ladder",
   "metadata": {},
   "source": [
    "![galaxyConfusion](../images/galaxy_confusion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.plot_precision_recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-illinois",
   "metadata": {},
   "source": [
    "![galaxyPr](../images/galaxy_pr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-check",
   "metadata": {},
   "source": [
    "We have all of the metrics for every run precalculated and at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "august-scope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparamcombo_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>repeat_index</th>\n",
       "      <th>predictor_id</th>\n",
       "      <th>metric</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>pstdev</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.175093</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.790476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.175093</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.790476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.657118</td>\n",
       "      <td>0.433796</td>\n",
       "      <td>0.101170</td>\n",
       "      <td>0.638489</td>\n",
       "      <td>0.576468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.098111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.774603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.626964</td>\n",
       "      <td>0.515694</td>\n",
       "      <td>0.050871</td>\n",
       "      <td>0.619902</td>\n",
       "      <td>0.587520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.103935</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.126159</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.844104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.094281</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.695238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.078121</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.767196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>loss</td>\n",
       "      <td>2.118411</td>\n",
       "      <td>0.551639</td>\n",
       "      <td>0.683482</td>\n",
       "      <td>0.824062</td>\n",
       "      <td>1.164704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.102203</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.128273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.757370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.123443</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.129110</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.748810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.754951</td>\n",
       "      <td>0.465973</td>\n",
       "      <td>0.118053</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>0.613510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.204544</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.072955</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.837302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.097822</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.861905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.108012</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.606985</td>\n",
       "      <td>0.564041</td>\n",
       "      <td>0.019458</td>\n",
       "      <td>0.603421</td>\n",
       "      <td>0.591483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.047140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.163037</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.898526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.164579</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.659524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.108637</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.748341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.761833</td>\n",
       "      <td>0.552645</td>\n",
       "      <td>0.095547</td>\n",
       "      <td>0.566346</td>\n",
       "      <td>0.626942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.620927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.933673</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.213995</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.700113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.072921</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.060827</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.815517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>loss</td>\n",
       "      <td>3.542673</td>\n",
       "      <td>0.412229</td>\n",
       "      <td>1.423016</td>\n",
       "      <td>0.649813</td>\n",
       "      <td>1.534905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166296</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.143297</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.865079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.127678</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.795351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.046291</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.778571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.048596</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.818543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.299485</td>\n",
       "      <td>0.292846</td>\n",
       "      <td>0.845627</td>\n",
       "      <td>0.706807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.067822</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.695614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.098111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.099442</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.710016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>loss</td>\n",
       "      <td>3.459070</td>\n",
       "      <td>0.547876</td>\n",
       "      <td>1.352021</td>\n",
       "      <td>0.636163</td>\n",
       "      <td>1.547703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.204275</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.744444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.056120</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.706349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.811224</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.068145</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.040406</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.790616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.473485</td>\n",
       "      <td>0.102240</td>\n",
       "      <td>0.620068</td>\n",
       "      <td>0.605394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.062361</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.933673</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.110120</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.811224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hyperparamcombo_id  job_id  repeat_index  predictor_id     metric  \\\n",
       "0                    8       8             0            22   accuracy   \n",
       "1                    8       8             0            22         f1   \n",
       "2                    8       8             0            22       loss   \n",
       "3                    8       8             0            22  precision   \n",
       "4                    8       8             0            22     recall   \n",
       "5                    8       8             0            22    roc_auc   \n",
       "6                    9       9             0            23   accuracy   \n",
       "7                    9       9             0            23         f1   \n",
       "8                    9       9             0            23       loss   \n",
       "9                    9       9             0            23  precision   \n",
       "10                   9       9             0            23     recall   \n",
       "11                   9       9             0            23    roc_auc   \n",
       "12                   8       8             1            24   accuracy   \n",
       "13                   8       8             1            24         f1   \n",
       "14                   8       8             1            24       loss   \n",
       "15                   8       8             1            24  precision   \n",
       "16                   8       8             1            24     recall   \n",
       "17                   8       8             1            24    roc_auc   \n",
       "18                   9       9             1            25   accuracy   \n",
       "19                   9       9             1            25         f1   \n",
       "20                   9       9             1            25       loss   \n",
       "21                   9       9             1            25  precision   \n",
       "22                   9       9             1            25     recall   \n",
       "23                   9       9             1            25    roc_auc   \n",
       "24                   8       8             2            26   accuracy   \n",
       "25                   8       8             2            26         f1   \n",
       "26                   8       8             2            26       loss   \n",
       "27                   8       8             2            26  precision   \n",
       "28                   8       8             2            26     recall   \n",
       "29                   8       8             2            26    roc_auc   \n",
       "30                   9       9             2            27   accuracy   \n",
       "31                   9       9             2            27         f1   \n",
       "32                   9       9             2            27       loss   \n",
       "33                   9       9             2            27  precision   \n",
       "34                   9       9             2            27     recall   \n",
       "35                   9       9             2            27    roc_auc   \n",
       "36                   8       8             3            28   accuracy   \n",
       "37                   8       8             3            28         f1   \n",
       "38                   8       8             3            28       loss   \n",
       "39                   8       8             3            28  precision   \n",
       "40                   8       8             3            28     recall   \n",
       "41                   8       8             3            28    roc_auc   \n",
       "42                   9       9             3            29   accuracy   \n",
       "43                   9       9             3            29         f1   \n",
       "44                   9       9             3            29       loss   \n",
       "45                   9       9             3            29  precision   \n",
       "46                   9       9             3            29     recall   \n",
       "47                   9       9             3            29    roc_auc   \n",
       "48                   8       8             4            30   accuracy   \n",
       "49                   8       8             4            30         f1   \n",
       "50                   8       8             4            30       loss   \n",
       "51                   8       8             4            30  precision   \n",
       "52                   8       8             4            30     recall   \n",
       "53                   8       8             4            30    roc_auc   \n",
       "54                   9       9             4            31   accuracy   \n",
       "55                   9       9             4            31         f1   \n",
       "56                   9       9             4            31       loss   \n",
       "57                   9       9             4            31  precision   \n",
       "58                   9       9             4            31     recall   \n",
       "59                   9       9             4            31    roc_auc   \n",
       "\n",
       "     maximum   minimum    pstdev    median      mean  \n",
       "0   1.000000  0.571429  0.175093  0.800000  0.790476  \n",
       "1   1.000000  0.571429  0.175093  0.800000  0.790476  \n",
       "2   0.657118  0.433796  0.101170  0.638489  0.576468  \n",
       "3   1.000000  0.500000  0.235702  1.000000  0.833333  \n",
       "4   1.000000  0.666667  0.157135  0.666667  0.777778  \n",
       "5   1.000000  0.666667  0.136083  0.833333  0.833333  \n",
       "6   0.800000  0.571429  0.098111  0.750000  0.707143  \n",
       "7   0.857143  0.666667  0.079808  0.800000  0.774603  \n",
       "8   0.626964  0.515694  0.050871  0.619902  0.587520  \n",
       "9   0.750000  0.500000  0.103935  0.666667  0.638889  \n",
       "10  1.000000  1.000000  0.000000  1.000000  1.000000  \n",
       "11  0.948980  0.666667  0.126159  0.916667  0.844104  \n",
       "12  0.800000  0.571429  0.094281  0.714286  0.695238  \n",
       "13  0.857143  0.666667  0.078121  0.777778  0.767196  \n",
       "14  2.118411  0.551639  0.683482  0.824062  1.164704  \n",
       "15  0.750000  0.500000  0.102203  0.636364  0.628788  \n",
       "16  1.000000  1.000000  0.000000  1.000000  1.000000  \n",
       "17  0.938776  0.666667  0.128273  0.666667  0.757370  \n",
       "18  0.857143  0.571429  0.123443  0.800000  0.742857  \n",
       "19  0.875000  0.571429  0.129110  0.800000  0.748810  \n",
       "20  0.754951  0.465973  0.118053  0.619605  0.613510  \n",
       "21  1.000000  0.500000  0.204544  0.777778  0.759259  \n",
       "22  1.000000  0.666667  0.157135  0.666667  0.777778  \n",
       "23  0.928571  0.750000  0.072955  0.833333  0.837302  \n",
       "24  1.000000  0.785714  0.097822  0.800000  0.861905  \n",
       "25  1.000000  0.750000  0.108012  0.800000  0.850000  \n",
       "26  0.606985  0.564041  0.019458  0.603421  0.591483  \n",
       "27  1.000000  0.900000  0.047140  1.000000  0.966667  \n",
       "28  1.000000  0.642857  0.163037  0.666667  0.769841  \n",
       "29  1.000000  0.833333  0.072717  0.862245  0.898526  \n",
       "30  0.800000  0.428571  0.164579  0.750000  0.659524  \n",
       "31  0.857143  0.600000  0.108637  0.787879  0.748341  \n",
       "32  0.761833  0.552645  0.095547  0.566346  0.626942  \n",
       "33  0.750000  0.428571  0.138643  0.684211  0.620927  \n",
       "34  1.000000  0.928571  0.033672  1.000000  0.976190  \n",
       "35  0.933673  0.416667  0.213995  0.750000  0.700113  \n",
       "36  0.892857  0.714286  0.072921  0.800000  0.802381  \n",
       "37  0.896552  0.750000  0.060827  0.800000  0.815517  \n",
       "38  3.542673  0.412229  1.423016  0.649813  1.534905  \n",
       "39  1.000000  0.600000  0.166296  0.866667  0.822222  \n",
       "40  1.000000  0.666667  0.143297  0.928571  0.865079  \n",
       "41  0.969388  0.666667  0.127678  0.750000  0.795351  \n",
       "42  0.821429  0.714286  0.046291  0.800000  0.778571  \n",
       "43  0.857143  0.750000  0.048596  0.848485  0.818543  \n",
       "44  0.975309  0.299485  0.292846  0.845627  0.706807  \n",
       "45  0.750000  0.600000  0.067822  0.736842  0.695614  \n",
       "46  1.000000  1.000000  0.000000  1.000000  1.000000  \n",
       "47  1.000000  0.666667  0.136083  0.833333  0.833333  \n",
       "48  0.800000  0.571429  0.098111  0.750000  0.707143  \n",
       "49  0.800000  0.571429  0.099442  0.758621  0.710016  \n",
       "50  3.459070  0.547876  1.352021  0.636163  1.547703  \n",
       "51  1.000000  0.500000  0.204275  0.733333  0.744444  \n",
       "52  0.785714  0.666667  0.056120  0.666667  0.706349  \n",
       "53  0.811224  0.666667  0.068145  0.666667  0.714853  \n",
       "54  0.800000  0.714286  0.040406  0.714286  0.742857  \n",
       "55  0.857143  0.750000  0.047423  0.764706  0.790616  \n",
       "56  0.722628  0.473485  0.102240  0.620068  0.605394  \n",
       "57  0.750000  0.600000  0.062361  0.650000  0.666667  \n",
       "58  1.000000  0.928571  0.033672  1.000000  0.976190  \n",
       "59  0.933673  0.666667  0.110120  0.833333  0.811224  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.metrics_aggregate_to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "suburban-industry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparamcombo_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>repeat_index</th>\n",
       "      <th>predictor_id</th>\n",
       "      <th>split</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>train</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.473485</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.620068</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>test</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>train</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.547876</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.811224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.459070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>test</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.636163</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>train</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.299485</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.845627</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>test</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>train</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.412229</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.969388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.542673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>test</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.649813</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.566346</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>train</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.552645</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>test</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.761833</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>train</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.606985</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.862245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.564041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>train</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.465973</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>test</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.754951</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>train</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.551639</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.824062</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>test</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.118411</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>train</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.515694</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.619902</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>test</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.626964</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.657118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>test</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.638489</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hyperparamcombo_id  job_id  repeat_index  predictor_id       split  \\\n",
       "29                   9       9             4            31       train   \n",
       "28                   9       9             4            31  validation   \n",
       "27                   9       9             4            31        test   \n",
       "26                   8       8             4            30       train   \n",
       "25                   8       8             4            30  validation   \n",
       "24                   8       8             4            30        test   \n",
       "23                   9       9             3            29       train   \n",
       "22                   9       9             3            29  validation   \n",
       "21                   9       9             3            29        test   \n",
       "20                   8       8             3            28       train   \n",
       "19                   8       8             3            28  validation   \n",
       "18                   8       8             3            28        test   \n",
       "16                   9       9             2            27  validation   \n",
       "17                   9       9             2            27       train   \n",
       "15                   9       9             2            27        test   \n",
       "14                   8       8             2            26       train   \n",
       "13                   8       8             2            26  validation   \n",
       "12                   8       8             2            26        test   \n",
       "11                   9       9             1            25       train   \n",
       "10                   9       9             1            25  validation   \n",
       "9                    9       9             1            25        test   \n",
       "8                    8       8             1            24       train   \n",
       "7                    8       8             1            24  validation   \n",
       "6                    8       8             1            24        test   \n",
       "5                    9       9             0            23       train   \n",
       "4                    9       9             0            23  validation   \n",
       "3                    9       9             0            23        test   \n",
       "1                    8       8             0            22  validation   \n",
       "2                    8       8             0            22       train   \n",
       "0                    8       8             0            22        test   \n",
       "\n",
       "    accuracy        f1      loss  precision    recall   roc_auc  \n",
       "29  0.714286  0.764706  0.473485   0.650000  0.928571  0.933673  \n",
       "28  0.800000  0.857143  0.620068   0.750000  1.000000  0.833333  \n",
       "27  0.714286  0.750000  0.722628   0.600000  1.000000  0.666667  \n",
       "26  0.750000  0.758621  0.547876   0.733333  0.785714  0.811224  \n",
       "25  0.800000  0.800000  3.459070   1.000000  0.666667  0.666667  \n",
       "24  0.571429  0.571429  0.636163   0.500000  0.666667  0.666667  \n",
       "23  0.821429  0.848485  0.299485   0.736842  1.000000  1.000000  \n",
       "22  0.800000  0.857143  0.845627   0.750000  1.000000  0.666667  \n",
       "21  0.714286  0.750000  0.975309   0.600000  1.000000  0.833333  \n",
       "20  0.892857  0.896552  0.412229   0.866667  0.928571  0.969388  \n",
       "19  0.800000  0.800000  3.542673   1.000000  0.666667  0.666667  \n",
       "18  0.714286  0.750000  0.649813   0.600000  1.000000  0.750000  \n",
       "16  0.800000  0.857143  0.566346   0.750000  1.000000  0.750000  \n",
       "17  0.750000  0.787879  0.552645   0.684211  0.928571  0.933673  \n",
       "15  0.428571  0.600000  0.761833   0.428571  1.000000  0.416667  \n",
       "14  0.785714  0.750000  0.606985   0.900000  0.642857  0.862245  \n",
       "13  0.800000  0.800000  0.564041   1.000000  0.666667  0.833333  \n",
       "12  1.000000  1.000000  0.603421   1.000000  1.000000  1.000000  \n",
       "11  0.857143  0.875000  0.465973   0.777778  1.000000  0.928571  \n",
       "10  0.800000  0.800000  0.619605   1.000000  0.666667  0.833333  \n",
       "9   0.571429  0.571429  0.754951   0.500000  0.666667  0.750000  \n",
       "8   0.714286  0.777778  0.551639   0.636364  1.000000  0.938776  \n",
       "7   0.800000  0.857143  0.824062   0.750000  1.000000  0.666667  \n",
       "6   0.571429  0.666667  2.118411   0.500000  1.000000  0.666667  \n",
       "5   0.750000  0.800000  0.515694   0.666667  1.000000  0.948980  \n",
       "4   0.800000  0.857143  0.619902   0.750000  1.000000  0.666667  \n",
       "3   0.571429  0.666667  0.626964   0.500000  1.000000  0.916667  \n",
       "1   0.800000  0.800000  0.657118   1.000000  0.666667  0.666667  \n",
       "2   1.000000  1.000000  0.433796   1.000000  1.000000  1.000000  \n",
       "0   0.571429  0.571429  0.638489   0.500000  0.666667  0.833333  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.metrics_to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-debate",
   "metadata": {},
   "source": [
    "We can also inspect the actual predictions for each split, which have been automatically `inverse_transform`'ed back from their encoded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instant-hours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': array(['bar', 'bar', 'spiral', 'spiral', 'bar', 'spiral', 'bar'],\n",
       "       dtype=object),\n",
       " 'validation': array(['bar', 'spiral', 'bar', 'spiral', 'bar'], dtype=object),\n",
       " 'train': array(['spiral', 'bar', 'spiral', 'spiral', 'spiral', 'spiral', 'bar',\n",
       "        'bar', 'spiral', 'bar', 'spiral', 'bar', 'bar', 'bar', 'spiral',\n",
       "        'bar', 'bar', 'bar', 'spiral', 'bar', 'bar', 'bar', 'bar',\n",
       "        'spiral', 'bar', 'bar', 'bar', 'bar'], dtype=object)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predictions[0].predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-adaptation",
   "metadata": {},
   "source": [
    "Let's dig into our recorded experiment to pull out the samples within the training set that were misclassified by comparing them to their actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "willing-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicted = predictor.predictions[0].predictions['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "synthetic-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = predictor.job.queue.splitset.samples['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "smaller-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actual = predictor.job.queue.splitset.label.to_numpy(samples=train_samples).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "international-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = train_predicted == train_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "other-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_misclassifications = np.argwhere(comparison==False).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "terminal-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_miss = [train_samples[miss] for miss in train_misclassifications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "proof-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_miss = aiqc.Dataset.Image.to_pillow(id=2, samples=train_samples_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-somewhere",
   "metadata": {},
   "source": [
    "Here is an example of a spiral that was missclassified as a bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "progressive-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=110x80 at 0x1755E1A90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_miss[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

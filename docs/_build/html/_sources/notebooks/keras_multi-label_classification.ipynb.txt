{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silver-toner",
   "metadata": {},
   "source": [
    "# Keras: Tabular Classify Multi-Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3ba61-1298-4355-a5e0-fe278acd8c7d",
   "metadata": {},
   "source": [
    "*Categorizing Plant Species with Multi-Label Classification of Phenotypes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-robinson",
   "metadata": {},
   "source": [
    "![farming](../images/vertical_farming.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3dd77-3c18-4acd-b851-da824c387b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc\n",
    "from aiqc import datum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-mapping",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-turkish",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-accident",
   "metadata": {},
   "source": [
    "This dataset is comprised of:\n",
    "\n",
    "* *Labels* = the species of the plant.\n",
    "* *Features* = phenotypes of the plant sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9eda3d-061f-44ab-bf1c-65e78e5ac641",
   "metadata": {},
   "source": [
    "Reference [Example Datasets](example_datasets.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hindu-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('iris.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "false-mumbai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-breakfast",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-desperate",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-butterfly",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information including how to work with non-tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-favor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298138a-eb92-4dd3-95b0-8ce522a5baea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.sparse=False`.\n",
      "   This would have generated 'scipy.sparse.csr.csr_matrix', causing Keras training to fail.\n",
      "\n",
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) featurecoder filters.\n",
      "\n",
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "\n",
      "=> Done. All feature column(s) have featurecoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitset = aiqc.Pipeline.Tabular(\n",
    "    # --- Data source ---\n",
    "    df_or_path = df\n",
    "    , dtype = None\n",
    "\n",
    "    # --- Label preprocessing ---\n",
    "    , label_column = 'species'\n",
    "    , label_interpolater = None\n",
    "    , label_encoder = dict(sklearn_preprocess = OneHotEncoder())\n",
    "\n",
    "    # --- Feature preprocessing ---\n",
    "    , feature_cols_excluded = 'species'\n",
    "    , feature_interpolaters = None\n",
    "    , feature_window = None\n",
    "    , feature_encoders = dict(\n",
    "        sklearn_preprocess = StandardScaler()\n",
    "        , dtypes = ['float64']\n",
    "    )\n",
    "    , feature_reshape_indices = None\n",
    "\n",
    "    # --- Stratification ---\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12\n",
    "    , fold_count = None\n",
    "    , bin_count = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-latest",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a25e74-2a2c-432d-98ac-3976c6e9fb74",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921f4cd-b473-45b5-8216-de95b45792be",
   "metadata": {},
   "source": [
    "Reference this great blog for machine learning cookbooks: [MachineLearningMastery.com \"Multi-Label Classification\"](https://machinelearningmastery.com/multi-label-classification-with-deep-learning/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd48ac94-8744-4078-bd94-bfe8c2836024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "racial-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):\n",
    "    m = tf.keras.models.Sequential()\n",
    "    m.add(l.Input(shape=features_shape))\n",
    "    m.add(l.Dense(units=hp['neuron_count'], activation='relu', kernel_initializer='he_uniform'))\n",
    "    m.add(l.Dense(units=label_shape[0], activation='softmax'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "robust-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss = loser\n",
    "        , optimizer = optimizer\n",
    "        , metrics = ['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        samples_train[\"features\"]\n",
    "        , samples_train[\"labels\"]\n",
    "        , validation_data = (\n",
    "            samples_evaluate[\"features\"]\n",
    "            , samples_evaluate[\"labels\"]\n",
    "        )\n",
    "        , verbose = 0\n",
    "        , batch_size = hp['batch_size']\n",
    "        , epochs = hp['epoch_count']\n",
    "        , callbacks=[tf.keras.callbacks.History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adaptive-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(\n",
    "    neuron_count    = [9, 12]\n",
    "    , batch_size    = [3]\n",
    "    , learning_rate = [0.03, 0.05]\n",
    "    , epoch_count   = [30, 60]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mechanical-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = aiqc.Experiment(\n",
    "    # --- Analysis type ---\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_multi\"\n",
    "    \n",
    "    # --- Model functions ---\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    "    , fn_lose = None #auto\n",
    "    , fn_optimize = None #auto\n",
    "    , fn_predict = None #auto\n",
    "    \n",
    "    # --- Training options ---\n",
    "    , repeat_count = 1\n",
    "    , hyperparameters = hyperparameters\n",
    "    , search_percent = None\n",
    "    \n",
    "    # --- Data source ---\n",
    "    , splitset_id = splitset.id\n",
    "    , foldset_id = None\n",
    "    , hide_test = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "treated-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ”® Training Models ðŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:49<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-gabriel",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Visualization & Metrics](visualization.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

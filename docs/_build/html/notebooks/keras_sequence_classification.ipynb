{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wireless-beach",
   "metadata": {},
   "source": [
    "# Keras: Times Series Classify Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-strengthening",
   "metadata": {},
   "source": [
    "*Binary Detection of Epileptic Seizures Using a Cohort of Sequence of Electroencephalography (EEG) Readings.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-aerospace",
   "metadata": {},
   "source": [
    "![waves](../images/waves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-expansion",
   "metadata": {},
   "source": [
    "Sequence data structures contain many observations (rows) for each sample (e.g. site, sensor, or patient). They are often used for grouping time-based observations into what is called a time series. However, sequences can also represent biological sequences like DNA and RNA.\n",
    "\n",
    "The cardinality of *many observations per sample* changes the dimensionality of the data from 2D to 3D. This effectively adds an additional layer of complexity to all aspects of data preparation. In this notebook, you'll see that, once a `Dataset.Sequence` has been ingested, the AIQC API allows you to work with multivariate 3D data as easily as if it were 2D. As an example, you can still apply encoders by dtype and column_name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-upset",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c683eaf-7ca6-44cc-adbe-5e02bd735d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc\n",
    "from aiqc import datum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-poetry",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-spanking",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43c390-d99a-476b-9fc4-a7c8c5fabee9",
   "metadata": {},
   "source": [
    "This dataset is comprised of:\n",
    "    \n",
    "- *Features* = a sequence of electroencephalogram (EEG) readings.\n",
    "- *Label* = presence of an epileptic seizure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7a0de2-5c54-417d-9317-364403ff710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('epilepsy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genetic-leeds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_0</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_169</th>\n",
       "      <th>sensor_170</th>\n",
       "      <th>sensor_171</th>\n",
       "      <th>sensor_172</th>\n",
       "      <th>sensor_173</th>\n",
       "      <th>sensor_174</th>\n",
       "      <th>sensor_175</th>\n",
       "      <th>sensor_176</th>\n",
       "      <th>sensor_177</th>\n",
       "      <th>seizure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>183</td>\n",
       "      <td>125</td>\n",
       "      <td>47</td>\n",
       "      <td>-32</td>\n",
       "      <td>-73</td>\n",
       "      <td>-105</td>\n",
       "      <td>-99</td>\n",
       "      <td>-72</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-202</td>\n",
       "      <td>-303</td>\n",
       "      <td>-365</td>\n",
       "      <td>-389</td>\n",
       "      <td>-406</td>\n",
       "      <td>-401</td>\n",
       "      <td>-366</td>\n",
       "      <td>-251</td>\n",
       "      <td>-143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284</td>\n",
       "      <td>276</td>\n",
       "      <td>268</td>\n",
       "      <td>261</td>\n",
       "      <td>254</td>\n",
       "      <td>241</td>\n",
       "      <td>232</td>\n",
       "      <td>223</td>\n",
       "      <td>212</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>-19</td>\n",
       "      <td>-57</td>\n",
       "      <td>-91</td>\n",
       "      <td>-118</td>\n",
       "      <td>-131</td>\n",
       "      <td>-140</td>\n",
       "      <td>-148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>373</td>\n",
       "      <td>555</td>\n",
       "      <td>580</td>\n",
       "      <td>548</td>\n",
       "      <td>502</td>\n",
       "      <td>433</td>\n",
       "      <td>348</td>\n",
       "      <td>276</td>\n",
       "      <td>216</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>-1032</td>\n",
       "      <td>-1108</td>\n",
       "      <td>-803</td>\n",
       "      <td>-377</td>\n",
       "      <td>-13</td>\n",
       "      <td>172</td>\n",
       "      <td>246</td>\n",
       "      <td>206</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791</td>\n",
       "      <td>703</td>\n",
       "      <td>538</td>\n",
       "      <td>76</td>\n",
       "      <td>-535</td>\n",
       "      <td>-1065</td>\n",
       "      <td>-1297</td>\n",
       "      <td>-1018</td>\n",
       "      <td>-525</td>\n",
       "      <td>-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-396</td>\n",
       "      <td>135</td>\n",
       "      <td>493</td>\n",
       "      <td>601</td>\n",
       "      <td>559</td>\n",
       "      <td>400</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>-141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>436</td>\n",
       "      <td>473</td>\n",
       "      <td>508</td>\n",
       "      <td>546</td>\n",
       "      <td>587</td>\n",
       "      <td>615</td>\n",
       "      <td>623</td>\n",
       "      <td>615</td>\n",
       "      <td>596</td>\n",
       "      <td>574</td>\n",
       "      <td>...</td>\n",
       "      <td>637</td>\n",
       "      <td>644</td>\n",
       "      <td>646</td>\n",
       "      <td>650</td>\n",
       "      <td>656</td>\n",
       "      <td>653</td>\n",
       "      <td>648</td>\n",
       "      <td>628</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_0  sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  \\\n",
       "0       232       183       125        47       -32       -73      -105   \n",
       "1       284       276       268       261       254       241       232   \n",
       "2       373       555       580       548       502       433       348   \n",
       "3       791       703       538        76      -535     -1065     -1297   \n",
       "4       436       473       508       546       587       615       623   \n",
       "\n",
       "   sensor_7  sensor_8  sensor_9  ...  sensor_169  sensor_170  sensor_171  \\\n",
       "0       -99       -72       -33  ...        -202        -303        -365   \n",
       "1       223       212       206  ...          64          15         -19   \n",
       "2       276       216       182  ...       -1032       -1108        -803   \n",
       "3     -1018      -525       -13  ...        -396         135         493   \n",
       "4       615       596       574  ...         637         644         646   \n",
       "\n",
       "   sensor_172  sensor_173  sensor_174  sensor_175  sensor_176  sensor_177  \\\n",
       "0        -389        -406        -401        -366        -251        -143   \n",
       "1         -57         -91        -118        -131        -140        -148   \n",
       "2        -377         -13         172         246         206         156   \n",
       "3         601         559         400         193           3        -141   \n",
       "4         650         656         653         648         628         608   \n",
       "\n",
       "   seizure  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9a1a5-258c-404a-94ed-920fabc14536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-killing",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-bracket",
   "metadata": {},
   "source": [
    "## a) High-Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-lafayette",
   "metadata": {},
   "source": [
    "Reference [High-Level API Docs](api_high_level.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excessive-dealing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_df = df[['seizure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tribal-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ndarray3D = df.drop(columns=['seizure']).to_numpy().reshape(1000,178,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reported-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Ingesting Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:05<00:00, 183.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) featurecoder filters.\n",
      "\n",
      "['0']\n",
      "\n",
      "=> Done. All feature column(s) have featurecoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitset = aiqc.Pipeline.Sequence.make(\n",
    "    # --- Label preprocessing ---\n",
    "    label_df_or_path = label_df\n",
    "    , label_dtype = None\n",
    "    , label_column = 'seizure'\n",
    "    , label_interpolater = None\n",
    "    , label_encoder = None\n",
    "    \n",
    "    # --- Feature preprocessing ---\n",
    "    , feature_ndarray3D_or_npyPath = seq_ndarray3D\n",
    "    , feature_dtype = None\n",
    "    , feature_cols_excluded = None\n",
    "    , feature_interpolaters = None\n",
    "    , feature_window = None\n",
    "    , feature_encoders = [\n",
    "        dict(columns='0', sklearn_preprocess=StandardScaler())\n",
    "    ]\n",
    "    , feature_reshape_indices = None\n",
    "\n",
    "    # --- Stratification ---\n",
    "    , size_test = 0.12\n",
    "    , size_validation = 0.22\n",
    "    , fold_count = None\n",
    "    , bin_count = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dying-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        hp['neuron_count']\n",
    "        , input_shape=(features_shape[0], features_shape[1])\n",
    "    ))\n",
    "    model.add(Dense(units=label_shape[0], activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "designed-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss=loser\n",
    "        , optimizer=optimizer\n",
    "        , metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        samples_train['features'], samples_train['labels']\n",
    "        , validation_data = (samples_evaluate['features'], samples_evaluate['labels'])\n",
    "        , verbose = 0\n",
    "        , batch_size = hp['batch_size']\n",
    "        , epochs = hp['epochs']\n",
    "        , callbacks = [History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "happy-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"neuron_count\": [25]\n",
    "    , \"batch_size\": [8]\n",
    "    , \"epochs\": [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "twenty-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = aiqc.Experiment.make(\n",
    "    # --- Analysis type ---\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_binary\"\n",
    "    \n",
    "    # --- Model functions ---\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    "    , fn_lose = None #auto\n",
    "    , fn_optimize = None #auto\n",
    "    , fn_predict = None #auto\n",
    "    \n",
    "    # --- Training options ---\n",
    "    , repeat_count = 2\n",
    "    , hyperparameters = hyperparameters\n",
    "    , search_percent = None\n",
    "    \n",
    "    # --- Data source ---\n",
    "    , splitset_id = splitset.id\n",
    "    , foldset_id = None\n",
    "    , hide_test = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "present-festival",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:24<00:00, 36.01s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-september",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Visualization & Metrics](visualization.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-fight",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-aggregate",
   "metadata": {},
   "source": [
    "## b) Low-Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intimate-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('epilepsy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "brilliant-exclusion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_df = df[['seizure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "facial-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ndarray3D = df.drop(columns=['seizure']).to_numpy().reshape(1000,178,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "planned-desert",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_tabular = aiqc.Dataset.Tabular.from_pandas(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "piano-necessity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = dataset_tabular.make_label(columns='seizure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accepting-indiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Ingesting Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:05<00:00, 194.69it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_sequence = aiqc.Dataset.Sequence.from_numpy(\n",
    "    ndarray3D_or_npyPath = seq_ndarray3D\n",
    "    , column_names = ['EEG']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "accompanied-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset_sequence.make_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dangerous-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = feature.make_encoderset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "employed-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) featurecoder filters.\n",
      "\n",
      "['EEG']\n",
      "\n",
      "=> Done. All feature column(s) have featurecoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoderset = encoderset.make_featurecoder(\n",
    "    sklearn_preprocess = StandardScaler()\n",
    "    , columns = ['EEG']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rural-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [feature.id]\n",
    "    , label_id = label.id\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "remarkable-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        hp['neuron_count']\n",
    "        , input_shape=(features_shape[0], features_shape[1])\n",
    "    ))\n",
    "    model.add(Dense(units=label_shape[0], activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "modular-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss=loser\n",
    "        , optimizer=optimizer\n",
    "        , metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        samples_train['features'], samples_train['labels']\n",
    "        , validation_data = (samples_evaluate['features'], samples_evaluate['labels'])\n",
    "        , verbose = 0\n",
    "        , batch_size = hp['batch_size']\n",
    "        , epochs = hp['epochs']\n",
    "        , callbacks = [History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "organic-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aiqc.Algorithm.make(\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_binary\"\n",
    "    , fn_build = fn_build\n",
    "    , fn_train = fn_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "earned-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"neuron_count\": [25]\n",
    "    , \"batch_size\": [8]\n",
    "    , \"epochs\": [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "christian-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = algorithm.make_hyperparamset(\n",
    "    hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "generous-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = algorithm.make_queue(\n",
    "    splitset_id = splitset.id\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , repeat_count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "governing-income",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [01:53<00:00, 28.32s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-joint",
   "metadata": {},
   "source": [
    "Reference [Low-Level API Docs](api_high_level.ipynb) for more information including how to work with non-tabular data and defining optimizers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

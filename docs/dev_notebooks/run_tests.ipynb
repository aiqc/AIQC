{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infinite-plaza",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade aiqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informative-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-placement",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "close-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall aiqc -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "challenging-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir('../..');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alien-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.chdir('/Users/layne/desktop/AIQC');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-sampling",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wound-commodity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/BernardoFernandes/Documents/GitHub/AIQC'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coupled-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: aiqc\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show aiqc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-induction",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informed-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleasant-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/BernardoFernandes/Documents/GitHub/AIQC/aiqc/__init__.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiqc.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "first-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Success - the following file path already exists on your system:\n",
      "/Users/BernardoFernandes/Library/Application Support/aiqc/\n",
      "\n",
      "\n",
      "=> Info - skipping folder creation as folder already exists at file path:\n",
      "/Users/BernardoFernandes/Library/Application Support/aiqc/\n",
      "\n",
      "\n",
      "=> Success - the following file path already exists on your system:\n",
      "/Users/BernardoFernandes/Library/Application Support/aiqc/\n",
      "\n",
      "\n",
      "=> Info - skipping as config file already exists at path:\n",
      "/Users/BernardoFernandes/Library/Application Support/aiqc/config.json\n",
      "\n",
      "\n",
      "=> Next run `aiqc.create_db()`.\n",
      "\n",
      "\n",
      "=> Skipping database file creation as a database file already exists at path:\n",
      "/Users/BernardoFernandes/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "=> Info - skipping table creation as the following tables already exist.['algorithm', 'dataset', 'encoderset', 'featurecoder', 'featureset', 'file', 'fold', 'foldset', 'hyperparamcombo', 'hyperparamset', 'image', 'job', 'jobset', 'label', 'labelcoder', 'queue', 'result', 'splitset', 'tabular']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aiqc.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "color-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Success - deleted database file at path:\n",
      "/Users/BernardoFernandes/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created database file at path:\n",
      "/Users/BernardoFernandes/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "💾  Success - created all database tables.  💾\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aiqc.Database().destroy_db(confirm=True, rebuild=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "senior-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc import tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-recycling",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aboriginal-garage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'ptratio', 'lstat']\n",
      "\n",
      "=> The remaining column(s) and dtype(s) can be used in downstream Featurecoder(s):\n",
      "{'chas': 'int64', 'rad': 'int64', 'tax': 'int64'}\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 1 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['chas', 'rad', 'tax']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pytorch_reg_queue = tests.make_test_queue('pytorch_regression', repeat_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "removed-study",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 4/4 [00:33<00:00,  8.27s/it]\n"
     ]
    }
   ],
   "source": [
    "pytorch_reg_queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-tracy",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adolescent-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pytorch_multi_queue = tests.make_test_queue('pytorch_multiclass', repeat_count=1, fold_count=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "plastic-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 4/4 [00:10<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "pytorch_multi_queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-meditation",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "duplicate-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'aj', 'ak', 'al', 'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au', 'av', 'aw', 'ax', 'ay', 'az', 'ba', 'bb', 'bc', 'bd', 'be', 'bf', 'bg', 'bh']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pytorch_binary_queue = tests.make_test_queue('pytorch_binary', repeat_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "generous-breed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 2/2 [00:03<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "pytorch_binary_queue.run_jobs(in_background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "secondary-sailing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pytorch_binary_queue.jobs[0].results[0].metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-criminal",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acknowledged-installation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'ptratio', 'lstat']\n",
      "\n",
      "=> The remaining column(s) and dtype(s) can be used in downstream Featurecoder(s):\n",
      "{'chas': 'int64', 'rad': 'int64', 'tax': 'int64'}\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 1 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['chas', 'rad', 'tax']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras_reg_queue = tests.make_test_queue('keras_regression', repeat_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "associate-swiss",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 4/4 [00:26<00:00,  6.63s/it]\n"
     ]
    }
   ],
   "source": [
    "keras_reg_queue.run_jobs(in_background=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-theology",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "infinite-shadow",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'aj', 'ak', 'al', 'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au', 'av', 'aw', 'ax', 'ay', 'az', 'ba', 'bb', 'bc', 'bd', 'be', 'bf', 'bg', 'bh']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras_binary_queue = tests.make_test_queue('keras_binary', repeat_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "developmental-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 8/8 [00:57<00:00,  7.18s/it]\n"
     ]
    }
   ],
   "source": [
    "keras_binary_queue.run_jobs(in_background=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-garlic",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "minimal-relative",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['petal_width']\n",
      "\n",
      "=> The remaining column(s) and dtype(s) can be used in downstream Featurecoder(s):\n",
      "{'petal_length': 'float64', 'sepal_length': 'float64', 'sepal_width': 'float64'}\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 1 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['sepal_length', 'sepal_width', 'petal_length']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras_multi_queue = tests.make_test_queue('keras_multiclass', repeat_count=1, fold_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "antique-period",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|████████████████████████████████████████| 24/24 [03:06<00:00,  7.77s/it]\n"
     ]
    }
   ],
   "source": [
    "keras_multi_queue.run_jobs(in_background=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-fraction",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "finished-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['TextData']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras_text_queue = tests.make_test_queue('keras_text_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "difficult-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 4/4 [01:14<00:00, 18.71s/it]\n"
     ]
    }
   ],
   "source": [
    "keras_text_queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-photography",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "infinite-three",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏱️ Validating Sequences 🧬: 100%|███████████| 1000/1000 [00:00<00:00, 1503873.79it/s]\n",
      "⏱️ Ingesting Sequences 🧬: 100%|████████████████| 1000/1000 [00:04<00:00, 228.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "\n",
      "=> Info - System overriding user input to set `sklearn_preprocess.copy=False`.\n",
      "   This saves memory when concatenating the output of many encoders.\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['0']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras_sequence_queue = tests.make_test_queue('keras_sequence_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "regular-mainstream",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 1/1 [00:19<00:00, 19.54s/it]\n"
     ]
    }
   ],
   "source": [
    "keras_sequence_queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-longitude",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "imported-asian",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖼️ Validating Images 🖼️: 100%|███████████████████████| 80/80 [00:44<00:00,  1.80it/s]\n",
      "🖼️ Ingesting Images 🖼️: 100%|████████████████████████| 80/80 [00:32<00:00,  2.46it/s]\n"
     ]
    }
   ],
   "source": [
    "keras_img_queue = tests.make_test_queue('keras_image_binary', repeat_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "greenhouse-petite",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "🔮 Training Models 🔮:   0%|                                                  | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #17 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.7, 'metric': 'val_accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.7, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'below', 'cutoff': 0.5, 'metric': 'val_loss'},\n",
      " {'above_or_below': 'below', 'cutoff': 0.5, 'metric': 'loss'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "🔮 Training Models 🔮:  25%|██████████▌                               | 1/4 [00:02<00:07,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch #40 ::\n",
      "Congratulations - satisfied early stopping thresholds defined in `MetricCutoff` callback:\n",
      "[{'above_or_below': 'above', 'cutoff': 0.7, 'metric': 'val_accuracy'},\n",
      " {'above_or_below': 'above', 'cutoff': 0.7, 'metric': 'accuracy'},\n",
      " {'above_or_below': 'below', 'cutoff': 0.5, 'metric': 'val_loss'},\n",
      " {'above_or_below': 'below', 'cutoff': 0.5, 'metric': 'loss'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 4/4 [01:04<00:00, 16.14s/it]\n"
     ]
    }
   ],
   "source": [
    "keras_img_queue.run_jobs(in_background=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-pendant",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "thirty-gasoline",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖼️ Validating Images 🖼️: 100%|███████████████████████| 80/80 [00:28<00:00,  2.78it/s]\n",
      "🖼️ Ingesting Images 🖼️: 100%|████████████████████████| 80/80 [00:29<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "pytorch_img_queue = tests.make_test_queue(\"pytorch_image_binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "romantic-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 1/1 [00:38<00:00, 38.09s/it]\n"
     ]
    }
   ],
   "source": [
    "pytorch_img_queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-richmond",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
